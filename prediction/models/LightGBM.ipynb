{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zym5oy5Qu5V4",
    "outputId": "3b5dd03f-2a84-4a12-f0fb-eb21b835df9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting synapseml\n",
      "  Downloading synapseml-1.0.11-py2.py3-none-any.whl.metadata (774 bytes)\n",
      "Downloading synapseml-1.0.11-py2.py3-none-any.whl (584 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/584.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/584.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/584.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.7/584.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: synapseml\n",
      "Successfully installed synapseml-1.0.11\n"
     ]
    }
   ],
   "source": [
    "!pip install synapseml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zcbr7_-tcZ-",
    "outputId": "be8920fb-9b4e-4e89-ef50-013b32e64bf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from synapse.ml.lightgbm import LightGBMRegressor\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from synapse.ml.lightgbm import LightGBMRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Initialize spark session :\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Random forest regressor\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.11.2\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)\n",
    "\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    return spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "data = load_data(\"data_preprocessed_V3.csv\")\n",
    "\n",
    "\n",
    "# Define LightGBM regressor\n",
    "lgbm = LightGBMRegressor(\n",
    "    labelCol=\"price\",\n",
    "    featuresCol=\"features\",\n",
    "    objective=\"regression\",\n",
    "    verbosity=-1,\n",
    "    boostingType=\"gbdt\"\n",
    ")\n",
    "\n",
    "\n",
    "# Step 1: Feature Selection using SelectKBest\n",
    "def select_features(data, target_col, k=10):\n",
    "    # Convert to Pandas for feature selection\n",
    "    pandas_df = data.toPandas()\n",
    "    X = pandas_df.drop(target_col, axis=1)\n",
    "    y = pandas_df[target_col]\n",
    "\n",
    "    # Apply SelectKBest\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    selector.fit(X, y)\n",
    "\n",
    "    # Get selected feature names\n",
    "    selected_features = X.columns[selector.get_support()].tolist()\n",
    "    return selected_features\n",
    "\n",
    "target_col = 'price'\n",
    "selected_features = select_features(data, target_col, k=10)\n",
    "\n",
    "# Step 2: Split data into train and test (before assembling features)\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Step 3: Define VectorAssembler for selected features\n",
    "assembler = VectorAssembler(inputCols=selected_features, outputCol=\"features\")\n",
    "\n",
    "\n",
    "# Define the pipeline (replace with your actual pipeline if needed)\n",
    "pipeline = Pipeline(stages=[assembler, lgbm])  \n",
    "\n",
    "# Build the param grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lgbm.learningRate, [0.01, 0.05, 0.1]) \\\n",
    "    .addGrid(lgbm.numLeaves, [15, 31, 63]) \\\n",
    "    .addGrid(lgbm.featureFraction, [0.8, 1.0]) \\\n",
    "    .addGrid(lgbm.maxDepth, [5, 10, -1]) \\\n",
    "    .addGrid(lgbm.lambdaL1, [0.0, 0.1]) \\\n",
    "    .addGrid(lgbm.lambdaL2, [0.0, 1.0]) \\\n",
    "    .addGrid(lgbm.baggingFraction, [0.7, 1.0]) \\\n",
    "    .addGrid(lgbm.baggingFreq, [0, 5]) \\\n",
    "    .build()\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"price\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Use TrainValidationSplit instead of CrossValidator\n",
    "tvs = TrainValidationSplit(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    trainRatio=0.8,\n",
    "    parallelism=4,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "tvsModel = tvs.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0y3ga7tyuExi",
    "outputId": "19284177-68c6-44e8-b46e-160d7daeec06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: {'rmse': 72112.70273157304, 'mae': 40468.73687482394, 'r2': 0.6310948468295978}\n",
      "Train data: {'rmse': 65192.40440527915, 'mae': 37111.00446411725, 'r2': 0.7053967781604382}\n"
     ]
    }
   ],
   "source": [
    "# 11. Evaluate on test data\n",
    "test_predictions = tvsModel.transform(test_data)\n",
    "rmse_test = evaluator.evaluate(test_predictions)\n",
    "mae_test = evaluator.evaluate(test_predictions, {evaluator.metricName: \"mae\"})\n",
    "r2_test = evaluator.evaluate(test_predictions, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "print(f\"Test data: {{'rmse': {rmse_test}, 'mae': {mae_test}, 'r2': {r2_test}}}\")\n",
    "\n",
    "# evaluate on train data :\n",
    "train_predictions = tvsModel.transform(train_data)\n",
    "rmse_train = evaluator.evaluate(train_predictions)\n",
    "mae_train = evaluator.evaluate(train_predictions, {evaluator.metricName: \"mae\"})\n",
    "r2_train = evaluator.evaluate(train_predictions, {evaluator.metricName: \"r2\"})\n",
    "\n",
    "print(f\"Train data: {{'rmse': {rmse_train}, 'mae': {mae_train}, 'r2': {r2_train}}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8fGxU6Vz6ng"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fo-bkihXBegE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
