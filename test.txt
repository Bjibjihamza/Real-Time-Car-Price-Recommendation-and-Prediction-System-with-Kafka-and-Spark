(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ ls
all.py  content_based_filtering.py  hybrid_recommendations.py  item_b_collab_filtering.py  user_b_collab_filtering.py
(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ cat content_based_filtering.py
import pandas as pd
import numpy as np
from cassandra.cluster import Cluster
from cassandra.query import SimpleStatement
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
from datetime import datetime
from pytz import UTC
import uuid
import logging

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Connect to Cassandra
try:
    cluster = Cluster(['localhost'])
    session = cluster.connect('cars_keyspace')
except Exception as e:
    logging.error(f"Error connecting to Cassandra: {e}")
    exit(1)

# Step 1: Extract and Preprocess Features
# Fetch user preferences
try:
    prefs_query = """
    SELECT user_id, preferred_brands, preferred_door_count, preferred_fuel_types,
           preferred_transmissions, budget_max, budget_min, mileage_max, mileage_min,
           preferred_years FROM user_preferences
    """
    prefs_rows = session.execute(SimpleStatement(prefs_query))
    prefs_data = [
        (
            str(row.user_id),
            row.preferred_brands or set(),
            row.preferred_door_count or set(),
            row.preferred_fuel_types or set(),
            row.preferred_transmissions or set(),
            row.budget_max or 0.0,
            row.budget_min or 0.0,
            row.mileage_max or 0.0,
            row.mileage_min or 0.0,
            row.preferred_years or set()
        ) for row in prefs_rows
    ]
except Exception as e:
    logging.error(f"Error querying user_preferences: {e}")
    cluster.shutdown()
    exit(1)

# Fetch car data
try:
    cars_query = """
    SELECT id, brand, door_count, fuel_type, transmission, price, mileage, year
    FROM cleaned_cars
    """
    cars_rows = session.execute(SimpleStatement(cars_query))
    cars_data = [
        (
            str(row.id),
            row.brand or 'unknown',
            row.door_count,
            row.fuel_type or 'unknown',
            row.transmission or 'unknown',
            row.price or np.nan,
            row.mileage or np.nan,
            row.year or np.nan
        ) for row in cars_rows
    ]
except Exception as e:
    logging.error(f"Error querying cleaned_cars: {e}")
    cluster.shutdown()
    exit(1)

# Create DataFrames
user_prefs_df = pd.DataFrame(
    prefs_data,
    columns=[
        'user_id', 'preferred_brands', 'preferred_door_count', 'preferred_fuel_types',
        'preferred_transmissions', 'budget_max', 'budget_min', 'mileage_max',
        'mileage_min', 'preferred_years'
    ]
)
cars_df = pd.DataFrame(
    cars_data,
    columns=['car_id', 'brand', 'door_count', 'fuel_type', 'transmission', 'price', 'mileage', 'year']
)

# Debug: Data summary
logging.info(f"User preferences rows: {len(user_prefs_df)}, Unique users: {user_prefs_df['user_id'].nunique()}")
logging.info(f"Cars rows: {len(cars_df)}, Unique cars: {cars_df['car_id'].nunique()}")
logging.info(f"Empty preferred_brands: {(user_prefs_df['preferred_brands'].apply(len) == 0).sum()}")
logging.info(f"Empty preferred_years: {(user_prefs_df['preferred_years'].apply(len) == 0).sum()}")

# Standardize categorical values
user_prefs_df['preferred_transmissions'] = user_prefs_df['preferred_transmissions'].apply(
    lambda x: {t.lower() for t in x}
)
cars_df['transmission'] = cars_df['transmission'].str.lower()
cars_df['brand'] = cars_df['brand'].str.lower()
cars_df['fuel_type'] = cars_df['fuel_type'].str.lower()

# Handle nulls in cars_df
cars_df['door_count'] = cars_df['door_count'].fillna(5).astype(int)  # Mode
cars_df['price'] = cars_df['price'].fillna(cars_df['price'].median(skipna=True))
cars_df['mileage'] = cars_df['mileage'].fillna(cars_df['mileage'].median(skipna=True))
cars_df['year'] = cars_df['year'].fillna(cars_df['year'].median(skipna=True))

# Debug: Unique values
logging.info(f"Unique door_count: {sorted(cars_df['door_count'].unique())}")
logging.info(f"Unique brands: {sorted(cars_df['brand'].unique())[:5]}...")
logging.info(f"Unique fuel types: {sorted(cars_df['fuel_type'].unique())}")
logging.info(f"Unique transmissions: {sorted(cars_df['transmission'].unique())}")

# Get unique categories
all_brands = sorted(set(cars_df['brand'].unique()) | set().union(*user_prefs_df['preferred_brands']))
door_counts = sorted(set(cars_df['door_count'].unique()) | set().union(*user_prefs_df['preferred_door_count']))
all_fuel_types = sorted(set(cars_df['fuel_type'].unique()) | set().union(*user_prefs_df['preferred_fuel_types']))
all_transmissions = sorted(set(cars_df['transmission'].unique()) | set().union(*user_prefs_df['preferred_transmissions']))

# Define feature columns
numerical_cols = ['budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years_mean', 'price', 'mileage', 'year']
categorical_cols = (
    [f'brand_{b}' for b in all_brands] +
    [f'door_count_{dc}' for dc in door_counts] +
    [f'fuel_type_{ft}' for ft in all_fuel_types] +
    [f'transmission_{tr}' for tr in all_transmissions]
)
all_cols = categorical_cols + numerical_cols

# Process user numerical features
user_prefs_df['preferred_years_mean'] = user_prefs_df['preferred_years'].apply(
    lambda x: np.mean(list(x)) if x else 2018
)
user_num_values = MinMaxScaler().fit_transform(
    user_prefs_df[['budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years_mean']]
)
user_num_df = pd.DataFrame(0.0, index=user_prefs_df['user_id'], columns=numerical_cols)
user_num_df[['budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years_mean']] = user_num_values

# Process car numerical features
car_num_values = MinMaxScaler().fit_transform(cars_df[['price', 'mileage', 'year']])
car_num_df = pd.DataFrame(0.0, index=cars_df['car_id'], columns=numerical_cols)
car_num_df[['price', 'mileage', 'year']] = car_num_values

# Process categorical features for users
user_cat_data = {col: np.zeros(len(user_prefs_df)) for col in categorical_cols}
for i, row in user_prefs_df.iterrows():
    for brand in row['preferred_brands']:
        if brand in all_brands:
            user_cat_data[f'brand_{brand}'][i] = 1
    for dc in row['preferred_door_count']:
        if dc in door_counts:
            user_cat_data[f'door_count_{dc}'][i] = 1
    for ft in row['preferred_fuel_types']:
        if ft in all_fuel_types:
            user_cat_data[f'fuel_type_{ft}'][i] = 1
    for tr in row['preferred_transmissions']:
        if tr in all_transmissions:
            user_cat_data[f'transmission_{tr}'][i] = 1
user_cat_df = pd.DataFrame(user_cat_data, index=user_prefs_df['user_id'])

# Process categorical features for cars
car_cat_data = {col: np.zeros(len(cars_df)) for col in categorical_cols}
for i, row in cars_df.iterrows():
    if row['brand'] in all_brands:
        car_cat_data[f'brand_{row["brand"]}'][i] = 1
    if row['door_count'] in door_counts:
        car_cat_data[f'door_count_{row["door_count"]}'][i] = 1
    if row['fuel_type'] in all_fuel_types:
        car_cat_data[f'fuel_type_{row["fuel_type"]}'][i] = 1
    if row['transmission'] in all_transmissions:
        car_cat_data[f'transmission_{row["transmission"]}'][i] = 1
car_cat_df = pd.DataFrame(car_cat_data, index=cars_df['car_id'])

# Combine features
user_features_df = pd.concat([user_cat_df, user_num_df], axis=1)
car_features_df = pd.concat([car_cat_df, car_num_df], axis=1)

# Verify features
logging.info(f"User features shape: {user_features_df.shape}")
logging.info(f"Car features shape: {car_features_df.shape}")
logging.info(f"Feature columns match: {user_features_df.columns.equals(car_features_df.columns)}")

# Step 2: Compute Cosine Similarity
similarity_matrix = cosine_similarity(user_features_df.values, car_features_df.values)
similarity_df = pd.DataFrame(
    similarity_matrix,
    index=user_features_df.index,
    columns=car_features_df.index
)

# Debug: Similarity matrix
logging.info(f"Similarity matrix shape: {similarity_df.shape}")
logging.info("Sample similarities (first 3 users, 3 cars):")
logging.info(similarity_df.iloc[:3, :3])

# Step 3: Generate Recommendations
# Fetch user-item interactions directly from Cassandra
try:
    views_query = "SELECT user_id, car_id FROM car_views_by_user"
    views_rows = session.execute(SimpleStatement(views_query))
    views_data = [(str(row.user_id), str(row.car_id)) for row in views_rows]
    
    favs_query = "SELECT user_id, car_id FROM favorite_cars_by_user"
    favs_rows = session.execute(SimpleStatement(favs_query))
    favs_data = [(str(row.user_id), str(row.car_id)) for row in favs_rows]
except Exception as e:
    logging.error(f"Error querying views/favorites: {e}")
    cluster.shutdown()
    exit(1)

# Create user-item interaction DataFrame
interactions = views_data + favs_data
user_item_df = pd.DataFrame(0, index=user_prefs_df['user_id'].unique(), columns=cars_df['car_id'].unique())
for user_id, car_id in interactions:
    if user_id in user_item_df.index and car_id in user_item_df.columns:
        user_item_df.loc[user_id, car_id] = 1

# Debug: Check shapes
logging.info(f"User-item matrix shape: {user_item_df.shape}")


# Generate recommendations
recommendations = []
for user_id in similarity_df.index:
    user_similarities = similarity_df.loc[user_id]
    
    # Filter out viewed/favorited cars
    if user_id in user_item_df.index:
        viewed_cars = user_item_df.loc[user_id][user_item_df.loc[user_id] > 0].index
        user_similarities = user_similarities.drop(viewed_cars, errors='ignore')
    
    # Get top-5 cars
    top_cars = user_similarities.nlargest(5)
    for rank, (car_id, score) in enumerate(top_cars.items(), 1):
        # Generate recommendation reason
        user_features = user_features_df.loc[user_id]
        car_features = car_features_df.loc[car_id]
        matches = []
        for col in user_features.index:
            if col.startswith('brand_') and user_features[col] > 0 and car_features[col] > 0:
                brand = col.replace('brand_', '')
                matches.append(f"{brand} brand")
            elif col.startswith('fuel_type_') and user_features[col] > 0 and car_features[col] > 0:
                fuel = col.replace('fuel_type_', '')
                matches.append(f"{fuel} fuel")
            elif col.startswith('transmission_') and user_features[col] > 0 and car_features[col] > 0:
                trans = col.replace('transmission_', '')
                matches.append(f"{trans} transmission")
            elif col.startswith('door_count_') and user_features[col] > 0 and car_features[col] > 0:
                doors = col.replace('door_count_', '')
                matches.append(f"{doors} doors")
        reason = f"Matches your preferences for {', '.join(matches) if matches else 'similar features'}"
        
        recommendations.append({
            'user_id': user_id,
            'car_id': car_id,
            'created_at': datetime.now(UTC).strftime('%Y-%m-%d %H:%M:%S+0000'),
            'rank': rank,
            'recommendation_reason': reason,
            'similarity_score': float(score)
        })

# Create recommendations DataFrame
rec_df = pd.DataFrame(recommendations)

# Debug: Recommendations summary
logging.info(f"Total recommendations: {len(rec_df)}")
logging.info("Sample recommendations:")
logging.info(rec_df[['user_id', 'car_id', 'rank', 'recommendation_reason', 'similarity_score']].head())

# Save to user_recommendations table
try:
    insert_query = """
    INSERT INTO user_recommendations (user_id, car_id, created_at, rank, recommendation_reason, similarity_score)
    VALUES (%s, %s, %s, %s, %s, %s)
    """
    for _, row in rec_df.iterrows():
        try:
            session.execute(
                insert_query,
                (
                    uuid.UUID(row['user_id']),
                    uuid.UUID(row['car_id']),
                    row['created_at'],
                    row['rank'],
                    row['recommendation_reason'],
                    row['similarity_score']
                )
            )
        except Exception as e:
            logging.error(f"Error inserting user_id={row['user_id']}, car_id={row['car_id']}, created_at={row['created_at']}: {e}")
except Exception as e:
    logging.error(f"Error inserting recommendations: {e}")
    cluster.shutdown()
    exit(1)

# Verify insertion
try:
    count = session.execute("SELECT COUNT(*) FROM user_recommendations").one()[0]
    logging.info(f"Total recommendations stored: {count}")
    rows = session.execute("SELECT user_id, car_id, rank, recommendation_reason, similarity_score FROM user_recommendations LIMIT 5")
    logging.info("\nSample recommendations from database:")
    for row in rows:
        logging.info(f"User: {row.user_id}, Car: {row.car_id}, Rank: {row.rank}, Reason: {row.recommendation_reason}, Score: {row.similarity_score:.2f}")
except Exception as e:
    logging.error(f"Error querying user_recommendations: {e}")

# Clean up
cluster.shutdown()
logging.info("Content-based filtering complete.")(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ python content_based_filtering.py
2025-05-13 13:34:31,990 - WARNING - Cluster.__init__ called with contact_points specified, but no load_balancing_policy. In the next major version, this will raise an error; please specify a load-balancing policy. (contact_points = ['localhost'], lbp = None)
2025-05-13 13:34:31,992 - WARNING - Downgrading core protocol version from 66 to 65 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
2025-05-13 13:34:31,993 - WARNING - Downgrading core protocol version from 65 to 5 for 127.0.0.1:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
2025-05-13 13:34:31,996 - INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '127.0.0.1:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
2025-05-13 13:34:32,025 - WARNING - Server warning: Read 633 live rows and 1472 tombstone cells for query SELECT brand, door_count, fuel_type, mileage, price, transmission, year FROM cars_keyspace.cleaned_cars LIMIT 5000 ALLOW FILTERING; token 9207834739780070790 (see tombstone_warn_threshold)
2025-05-13 13:34:32,028 - INFO - User preferences rows: 55, Unique users: 55
2025-05-13 13:34:32,029 - INFO - Cars rows: 633, Unique cars: 633
2025-05-13 13:34:32,029 - INFO - Empty preferred_brands: 1
2025-05-13 13:34:32,030 - INFO - Empty preferred_years: 3
2025-05-13 13:34:32,033 - INFO - Unique door_count: [2, 3, 4, 5]
2025-05-13 13:34:32,033 - INFO - Unique brands: ['abarth', 'alfa romeo', 'alfa-romeo', 'audi', 'bentley']...
2025-05-13 13:34:32,034 - INFO - Unique fuel types: ['diesel', 'essence', 'hybride', 'unknown']
2025-05-13 13:34:32,034 - INFO - Unique transmissions: ['automatique', 'manuelle', 'unknown']
2025-05-13 13:34:32,083 - INFO - User features shape: (55, 67)
2025-05-13 13:34:32,083 - INFO - Car features shape: (633, 67)
2025-05-13 13:34:32,083 - INFO - Feature columns match: True
2025-05-13 13:34:32,091 - INFO - Similarity matrix shape: (55, 633)
2025-05-13 13:34:32,091 - INFO - Sample similarities (first 3 users, 3 cars):
2025-05-13 13:34:32,091 - INFO - car_id                                7fa6de76-d72c-4b2b-a0b6-082740b340e7  8591128e-a8ad-4365-8d98-3006b14f39aa  06c110b1-9e53-4785-9db7-171c9ce7f033
user_id                                                                                                                                               
588f2dc3-c048-4c61-a241-3bcd654a4404                              0.348669                              0.176112                              0.348483
820a5b09-d987-4f15-a965-2777fd5c013e                              0.191430                              0.386764                              0.191328
9dd85bbf-d0ba-47a5-a4d6-a467d78d5fca                              0.000000                              0.000000                              0.000000
2025-05-13 13:34:32,120 - INFO - User-item matrix shape: (55, 633)
2025-05-13 13:34:32,250 - INFO - Total recommendations: 275
2025-05-13 13:34:32,250 - INFO - Sample recommendations:
2025-05-13 13:34:32,251 - INFO -                                 user_id                                car_id  rank                              recommendation_reason  similarity_score
0  588f2dc3-c048-4c61-a241-3bcd654a4404  531f113b-9318-4a12-9fba-94118c5c93b8     1  Matches your preferences for volkswagen brand,...          0.689336
1  588f2dc3-c048-4c61-a241-3bcd654a4404  ddd9b770-817d-40cb-993f-d3366dea8dcb     2  Matches your preferences for 3 doors, essence ...          0.556392
2  588f2dc3-c048-4c61-a241-3bcd654a4404  79ad63e7-311e-486d-ae2f-445b43777af2     3  Matches your preferences for volkswagen brand,...          0.555743
3  588f2dc3-c048-4c61-a241-3bcd654a4404  21ff0142-15f6-4142-91eb-163478e9f020     4  Matches your preferences for volkswagen brand,...          0.552816
4  588f2dc3-c048-4c61-a241-3bcd654a4404  b6d67f3c-a067-4e6b-ba14-ffa3bf46b010     5  Matches your preferences for volkswagen brand,...          0.551419
2025-05-13 13:34:32,477 - WARNING - Server warning: Aggregation query used without partition key
2025-05-13 13:34:32,477 - INFO - Total recommendations stored: 283
2025-05-13 13:34:32,479 - INFO - 
Sample recommendations from database:
2025-05-13 13:34:32,479 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 21ff0142-15f6-4142-91eb-163478e9f020, Rank: 4, Reason: Matches your preferences for volkswagen brand, essence fuel, manuelle transmission, Score: 0.55
2025-05-13 13:34:32,479 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 2f4688ff-eb97-4676-81cf-83835b9c4d19, Rank: 3, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.57), Score: 0.47
2025-05-13 13:34:32,479 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 531f113b-9318-4a12-9fba-94118c5c93b8, Rank: 1, Reason: Matches your preferences for volkswagen brand, 3 doors, diesel fuel, manuelle transmission, Score: 0.69
2025-05-13 13:34:32,479 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 79ad63e7-311e-486d-ae2f-445b43777af2, Rank: 3, Reason: Matches your preferences for volkswagen brand, essence fuel, manuelle transmission, Score: 0.56
2025-05-13 13:34:32,479 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 804cebfd-670c-47b1-b54a-20ff20d16200, Rank: 2, Reason: Based on your viewing - search and favorite patterns, Score: 0.84
2025-05-13 13:34:32,479 - INFO - Content-based filtering complete.
(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ ls
all.py  content_based_filtering.py  hybrid_recommendations.py  item_b_collab_filtering.py  user_b_collab_filtering.py
(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ cat item_b_collab_filtering.py
import pandas as pd
from cassandra.cluster import Cluster
from cassandra.query import SimpleStatement
from cassandra.policies import DCAwareRoundRobinPolicy
from datetime import datetime
import pytz
import uuid
import os
import logging
import random
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Initialize output directory
DATA_DIR = "../data"
os.makedirs(DATA_DIR, exist_ok=True)

# Connect to Cassandra
try:
    cluster = Cluster(
        ['localhost'],
        protocol_version=4,
        load_balancing_policy=DCAwareRoundRobinPolicy(local_dc='datacenter1')
    )
    session = cluster.connect('cars_keyspace')
except Exception as e:
    logging.error(f"Error connecting to Cassandra: {e}")
    exit(1)

# Fetch views and favorites
try:
    views_query = "SELECT user_id, car_id, view_timestamp FROM car_views_by_user"
    views_rows = session.execute(SimpleStatement(views_query))
    views_data = [(str(row.user_id), str(row.car_id), row.view_timestamp) for row in views_rows]
    
    favs_query = "SELECT user_id, car_id, added_timestamp FROM favorite_cars_by_user"
    favs_rows = session.execute(SimpleStatement(favs_query))
    favs_data = [(str(row.user_id), str(row.car_id), row.added_timestamp) for row in favs_rows]
except Exception as e:
    logging.error(f"Error querying Cassandra: {e}")
    cluster.shutdown()
    exit(1)

# Create DataFrames
views_df = pd.DataFrame(views_data, columns=['user_id', 'car_id', 'view_timestamp'])
favs_df = pd.DataFrame(favs_data, columns=['user_id', 'car_id', 'added_timestamp'])

# Debug: Data summary
logging.info(f"Views rows: {len(views_df)}, Unique users: {views_df['user_id'].nunique()}, Unique cars: {views_df['car_id'].nunique()}")
logging.info(f"Favorites rows: {len(favs_df)}, Unique users: {favs_df['user_id'].nunique()}, Unique cars: {favs_df['car_id'].nunique()}")

# Build user-item interaction matrix
# Combine views (weight=1) and favorites (weight=2)
interactions = []
for _, row in views_df.iterrows():
    if pd.notnull(row['view_timestamp']):
        interactions.append((row['user_id'], row['car_id'], 1.0, row['view_timestamp']))
    else:
        logging.warning(f"Skipping view for user {row['user_id']}, car {row['car_id']}: Invalid timestamp")
for _, row in favs_df.iterrows():
    if pd.notnull(row['added_timestamp']):
        interactions.append((row['user_id'], row['car_id'], 2.0, row['added_timestamp']))
    else:
        logging.warning(f"Skipping favorite for user {row['user_id']}, car {row['car_id']}: Invalid timestamp")

# Weight interactions by recency (decay over 30 days)
current_time = datetime.now(pytz.UTC)
def recency_weight(timestamp):
    try:
        # Convert timestamp to tz-aware UTC if tz-naive
        if timestamp.tzinfo is None:
            timestamp = pytz.UTC.localize(timestamp)
        days_old = (current_time - timestamp).total_seconds() / (24 * 3600)
        return max(0.5, 1.0 - (days_old / 30.0))  # Minimum weight 0.5
    except Exception as e:
        logging.warning(f"Invalid timestamp {timestamp}: {e}, using default weight 0.5")
        return 0.5

interactions = [(user_id, car_id, score * recency_weight(timestamp), timestamp) 
                for user_id, car_id, score, timestamp in interactions]
interaction_df = pd.DataFrame(interactions, columns=['user_id', 'car_id', 'score', 'timestamp'])

# Pivot to create user-item matrix
user_item_matrix = pd.pivot_table(
    interaction_df,
    values='score',
    index='user_id',
    columns='car_id',
    aggfunc='sum',
    fill_value=0
)

# Compute item-to-item similarity using cosine similarity
car_similarity_matrix = cosine_similarity(user_item_matrix.T)
car_ids = user_item_matrix.columns
car_similarity_df = pd.DataFrame(car_similarity_matrix, index=car_ids, columns=car_ids)

# Debug: Similarity matrix info
logging.info(f"Car similarity matrix shape: {car_similarity_df.shape}")

# Get unique users
users = set(views_df['user_id']).union(set(favs_df['user_id']))

# Generate recommendations
recommendations = {}
reason = "Based on your viewing - search and favorite patterns"
max_recs_per_user = 10
recs_to_add = 3

for user_id in users:
    try:
        # Get user interactions
        user_views = set(views_df[views_df['user_id'] == user_id]['car_id'])
        user_favs = set(favs_df[favs_df['user_id'] == user_id]['car_id'])
        user_interactions = user_views.union(user_favs)
        
        # Get existing recommendations
        existing_recs_query = """
            SELECT car_id FROM user_recommendations
            WHERE user_id = %s AND recommendation_reason = %s
            ALLOW FILTERING
        """
        existing_recs = session.execute(existing_recs_query, (uuid.UUID(user_id), reason))
        existing_car_ids = set(str(row.car_id) for row in existing_recs)
        
        # Exclude viewed, favorited, or previously recommended cars
        excluded_cars = user_views.union(user_favs).union(existing_car_ids)
        
        # Compute collaborative filtering scores
        candidate_scores = {}
        for car_id in user_interactions:
            if car_id in car_similarity_df.index:
                similar_cars = car_similarity_df.loc[car_id].dropna()
                for similar_car_id, sim_score in similar_cars.items():
                    if similar_car_id not in excluded_cars and sim_score > 0:
                        candidate_scores[similar_car_id] = candidate_scores.get(similar_car_id, 0) + sim_score
        
        # Normalize scores (0.0 to 0.9)
        if candidate_scores:
            max_sim_score = max(candidate_scores.values())
            candidate_scores = {car_id: (score / max_sim_score) * 0.9 for car_id, score in candidate_scores.items()}
        else:
            # Fallback: Recommend popular cars
            popular_cars_query = """
                SELECT car_id, COUNT(*) as fav_count FROM favorite_cars_by_user
                GROUP BY car_id LIMIT 10
            """
            popular_cars = session.execute(SimpleStatement(popular_cars_query))
            candidate_scores = {str(row.car_id): 0.5 for row in popular_cars}
        
        # Select top recommendations (up to 10, but we’ll filter to 3 later)
        top_recs = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)[:10]
        recommendations[user_id] = top_recs
    except Exception as e:
        logging.error(f"Error generating recommendations for user {user_id}: {e}")
        recommendations[user_id] = []

# Debug: Sample recommendations
logging.info("\nSample recommendations:")
for user_id in list(recommendations.keys())[:3]:
    logging.info(f"User {user_id}: {recommendations[user_id]}")

# Insert recommendations: Add exactly 3 per user, max 10 with specific reason
current_time = datetime.now(pytz.UTC)
for user_id, recs in recommendations.items():
    if not recs:
        logging.info(f"No recommendations for user {user_id}")
        continue
    
    try:
        user_id_uuid = uuid.UUID(user_id)
        
        # Fetch existing recommendations for this user with the specific reason
        query = """
            SELECT car_id, created_at
            FROM user_recommendations
            WHERE user_id = %s AND recommendation_reason = %s
            ALLOW FILTERING
        """
        existing_recs = session.execute(query, (user_id_uuid, reason))
        existing_recs_list = [(row.car_id, row.created_at) for row in existing_recs]
        current_count = len(existing_recs_list)
        existing_car_ids = set(str(car_id) for car_id, _ in existing_recs_list)
        
        logging.info(f"User {user_id}: {current_count} existing recommendations")
        
        # Filter out new recommendations that are already in existing_car_ids
        new_recs = [(car_id, score) for car_id, score in recs if car_id not in existing_car_ids]
        
        # Select exactly 3 new recommendations (or fewer if not enough)
        recs_to_insert = new_recs[:recs_to_add]
        
        # If adding new recommendations would exceed the limit, delete random existing ones
        if current_count + len(recs_to_insert) > max_recs_per_user:
            excess_recs = (current_count + len(recs_to_insert)) - max_recs_per_user
            recs_to_delete = random.sample(existing_recs_list, min(excess_recs, current_count))
            logging.info(f"User {user_id}: Deleting {len(recs_to_delete)} random recommendations to stay within {max_recs_per_user} limit")
            
            # Delete selected recommendations
            for car_id, _ in recs_to_delete:
                session.execute(
                    """
                    DELETE FROM user_recommendations
                    WHERE user_id = %s AND car_id = %s
                    """,
                    (user_id_uuid, car_id)
                )
        
        # Insert new recommendations
        for rank, (car_id, score) in enumerate(recs_to_insert, 1):
            try:
                car_id_uuid = uuid.UUID(car_id)
                session.execute(
                    """
                    INSERT INTO user_recommendations (user_id, car_id, created_at, rank, similarity_score, recommendation_reason)
                    VALUES (%s, %s, %s, %s, %s, %s)
                    """,
                    (user_id_uuid, car_id_uuid, current_time, rank, float(score), reason)
                )
                logging.info(f"Inserted recommendation for user {user_id}, car {car_id}, rank {rank}, score {score:.2f}")
            except Exception as e:
                logging.error(f"Error inserting recommendation for user {user_id}, car {car_id}: {e}")
        
        logging.info(f"User {user_id}: Added {len(recs_to_insert)} new recommendations")
    except Exception as e:
        logging.error(f"Error processing recommendations for user {user_id}: {e}")

# Verify insertion
try:
    rows = session.execute("SELECT user_id, car_id, rank, similarity_score, recommendation_reason FROM user_recommendations LIMIT 10")
    logging.info("\nSample recommendations in database:")
    for row in rows:
        logging.info(f"User: {row.user_id}, Car: {row.car_id}, Rank: {row.rank}, Score: {row.similarity_score:.2f}, Reason: {row.recommendation_reason}")
    count = session.execute("SELECT COUNT(*) FROM user_recommendations").one()[0]
    logging.info(f"Total recommendations stored: {count}")
except Exception as e:
    logging.error(f"Error querying user_recommendations: {e}")

# Clean up
cluster.shutdown()
logging.info("Recommendation process complete.")(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ python  item_b_collab_filtering.py
/home/hamzabji/projects/cars_recommandation_pipeline/spark/models/recommendations/item_b_collab_filtering.py:23: DeprecationWarning: Legacy execution parameters will be removed in 4.0. Consider using execution profiles.
  cluster = Cluster(
2025-05-13 13:34:50,442 - INFO - Views rows: 157, Unique users: 52, Unique cars: 132
2025-05-13 13:34:50,443 - INFO - Favorites rows: 109, Unique users: 53, Unique cars: 80
2025-05-13 13:34:50,498 - INFO - Car similarity matrix shape: (191, 191)
2025-05-13 13:34:50,521 - ERROR - Error generating recommendations for user 7ee4dfe8-97ff-48eb-b428-e41b6260f12d: Error from server: code=2200 [Invalid query] message="Group by is currently only supported on the columns of the PRIMARY KEY, got car_id"
2025-05-13 13:34:50,546 - ERROR - Error generating recommendations for user d27aa11a-f9eb-4bed-a706-02da891bbfe8: Error from server: code=2200 [Invalid query] message="Group by is currently only supported on the columns of the PRIMARY KEY, got car_id"
2025-05-13 13:34:50,554 - ERROR - Error generating recommendations for user 588f2dc3-c048-4c61-a241-3bcd654a4404: Error from server: code=2200 [Invalid query] message="Group by is currently only supported on the columns of the PRIMARY KEY, got car_id"
2025-05-13 13:34:50,587 - ERROR - Error generating recommendations for user b133408f-e3cb-4e91-b358-180918725c1f: Error from server: code=2200 [Invalid query] message="Group by is currently only supported on the columns of the PRIMARY KEY, got car_id"
2025-05-13 13:34:50,602 - ERROR - Error generating recommendations for user 8230e33b-4361-45b8-9a0e-622122e3f86d: Error from server: code=2200 [Invalid query] message="Group by is currently only supported on the columns of the PRIMARY KEY, got car_id"
2025-05-13 13:34:50,641 - ERROR - Error generating recommendations for user 74dff716-592f-4bbb-97e3-10493ec9018a: Error from server: code=2200 [Invalid query] message="Group by is currently only supported on the columns of the PRIMARY KEY, got car_id"
2025-05-13 13:34:50,660 - INFO - 
Sample recommendations:
2025-05-13 13:34:50,660 - INFO - User 2cb0eb07-3011-4cc3-888e-576a49a5250e: [('5935813a-f90f-4620-883e-56f677cbf278', 0.9), ('eb864504-2a36-45d7-9bde-34be108ec67b', 0.9), ('fb08a35e-7ecf-4c5a-a42f-b8e1edd9e89b', 0.8725548151198061), ('c5f23d61-b448-4a53-a510-0b2739867947', 0.8559968382607369), ('9a9c8d75-c742-4b4d-abb0-7751fa5ac878', 0.7489643227163674), ('085cb095-48b7-40b9-a060-c638b15a5744', 0.6977954786440441), ('0011e958-8606-46ae-8b15-8e3c5ba4f522', 0.4817869182151983), ('17414ad1-c07e-4f30-986e-9cc4b96dcc42', 0.4600639750396689), ('23020927-6653-406a-9963-916e692de061', 0.4600639750396689), ('753b61d4-f830-4549-9bea-c2ed4b8aee89', 0.4600639750396689)]
2025-05-13 13:34:50,660 - INFO - User 3943b611-9f26-48e6-9d35-2e14bac32e0c: [('17414ad1-c07e-4f30-986e-9cc4b96dcc42', 0.9), ('23020927-6653-406a-9963-916e692de061', 0.9), ('753b61d4-f830-4549-9bea-c2ed4b8aee89', 0.9), ('9af06ab2-e8a4-4498-a23e-493b6570cc8a', 0.9), ('af34d9e8-d55a-43d1-9dd5-a8316fc5f778', 0.9), ('f282f318-b6bf-4744-b9ec-8d3aa2e7fc22', 0.9), ('fb9fd644-d488-4a10-86b4-bebd64f94622', 0.9), ('242d3571-73ff-48ff-9bea-e978f8287859', 0.647732346516327), ('2ad560d1-331d-40b8-b6a3-5efc55036255', 0.6363961030678927), ('fb08a35e-7ecf-4c5a-a42f-b8e1edd9e89b', 0.5601790985848667)]
2025-05-13 13:34:50,660 - INFO - User f929047e-6c11-425f-bc2e-a4ddb03a0caf: [('9bb51d47-9dfe-439a-aff5-cd87450ad1ba', 0.9), ('c5e00a69-eb0c-44c4-8e3c-aabd4c34ba3f', 0.9), ('059cbb09-48dd-4457-8761-6cce8cf6711a', 0.15287120732027945), ('147c6d7a-4236-4038-8074-2687bb2f1486', 0.15287120732027945), ('840afcf9-2e63-4a91-bd9e-0ef4e7ff63e1', 0.15287120732027945), ('9acb6187-ac8c-4bcf-87e8-8db1b5785458', 0.15287120732027945), ('c2fc8e88-0833-4bea-a90f-9202dd95c8b1', 0.15287120732027945), ('7b74eda3-a719-4f78-ba8d-a2c9a6f28ca3', 0.10809626734434417), ('804cebfd-670c-47b1-b54a-20ff20d16200', 0.107872777877836)]
2025-05-13 13:34:50,661 - INFO - User 2cb0eb07-3011-4cc3-888e-576a49a5250e: 0 existing recommendations
2025-05-13 13:34:50,662 - INFO - Inserted recommendation for user 2cb0eb07-3011-4cc3-888e-576a49a5250e, car 5935813a-f90f-4620-883e-56f677cbf278, rank 1, score 0.90
2025-05-13 13:34:50,663 - INFO - Inserted recommendation for user 2cb0eb07-3011-4cc3-888e-576a49a5250e, car eb864504-2a36-45d7-9bde-34be108ec67b, rank 2, score 0.90
2025-05-13 13:34:50,664 - INFO - Inserted recommendation for user 2cb0eb07-3011-4cc3-888e-576a49a5250e, car fb08a35e-7ecf-4c5a-a42f-b8e1edd9e89b, rank 3, score 0.87
2025-05-13 13:34:50,664 - INFO - User 2cb0eb07-3011-4cc3-888e-576a49a5250e: Added 3 new recommendations
2025-05-13 13:34:50,665 - INFO - User 3943b611-9f26-48e6-9d35-2e14bac32e0c: 0 existing recommendations
2025-05-13 13:34:50,666 - INFO - Inserted recommendation for user 3943b611-9f26-48e6-9d35-2e14bac32e0c, car 17414ad1-c07e-4f30-986e-9cc4b96dcc42, rank 1, score 0.90
2025-05-13 13:34:50,667 - INFO - Inserted recommendation for user 3943b611-9f26-48e6-9d35-2e14bac32e0c, car 23020927-6653-406a-9963-916e692de061, rank 2, score 0.90
2025-05-13 13:34:50,669 - INFO - Inserted recommendation for user 3943b611-9f26-48e6-9d35-2e14bac32e0c, car 753b61d4-f830-4549-9bea-c2ed4b8aee89, rank 3, score 0.90
2025-05-13 13:34:50,700 - INFO - Inserted recommendation for user e1dd8d8d-40a0-4ce5-a68a-ba421650b528, car 14ffcc8b-c604-4b3d-9648-acab09b28733, rank 1, score 0.90
2025-05-13 13:34:50,701 - INFO - Inserted recommendation for user e1dd8d8d-40a0-4ce5-a68a-ba421650b528, car 48819253-430c-41b0-bc3c-6c7e0fa0dc0d, rank 2, score 0.82
2025-05-13 13:34:50,702 - INFO - Inserted recommendation for user e1dd8d8d-40a0-4ce5-a68a-ba421650b528, car b0fd793b-1b36-4bbf-b3ba-a370d17fef5f, rank 3, score 0.82
2025-05-13 13:34:50,702 - INFO - User e1dd8d8d-40a0-4ce5-a68a-ba421650b528: Added 3 new recommendations
2025-05-13 13:34:50,703 - INFO - User 0baa6ebe-7724-4305-94e2-c4894225dedd: 0 existing recommendations
2025-05-13 13:34:50,704 - INFO - Inserted recommendation for user 0baa6ebe-7724-4305-94e2-c4894225dedd, car 22151b8c-85c4-4861-8a20-109c14f67bb2, rank 1, score 0.90
2025-05-13 13:34:50,705 - INFO - Inserted recommendation for user 0baa6ebe-7724-4305-94e2-c4894225dedd, car c3b30e30-4caa-482c-9814-ca3bdf4176b8, rank 2, score 0.90
2025-05-13 13:34:50,706 - INFO - Inserted recommendation for user 0baa6ebe-7724-4305-94e2-c4894225dedd, car f0cc38ba-80ed-4092-9859-304a9c1ec2e3, rank 3, score 0.90
2025-05-13 13:34:50,870 - INFO - User d1418628-46ac-4b23-b8a2-4649b938030b: 0 existing recommendations
2025-05-13 13:34:50,871 - INFO - Inserted recommendation for user d1418628-46ac-4b23-b8a2-4649b938030b, car da1b1c23-4645-4865-9b52-9f5f637904df, rank 1, score 0.90
2025-05-13 13:34:50,871 - INFO - Inserted recommendation for user d1418628-46ac-4b23-b8a2-4649b938030b, car fc0610b4-d83f-4fa5-81ee-b3e9228d8086, rank 2, score 0.90
2025-05-13 13:34:50,872 - INFO - Inserted recommendation for user d1418628-46ac-4b23-b8a2-4649b938030b, car ff632c82-66fe-4785-a858-602ee1ef9ad5, rank 3, score 0.90
2025-05-13 13:34:50,872 - INFO - User d1418628-46ac-4b23-b8a2-4649b938030b: Added 3 new recommendations
2025-05-13 13:34:50,874 - INFO - User 4a36fcf0-b382-412d-b95f-8075261a1b5c: 0 existing recommendations
2025-05-13 13:34:50,875 - INFO - Inserted recommendation for user 4a36fcf0-b382-412d-b95f-8075261a1b5c, car 0004fa3a-8eab-40b2-9654-9e052193ac50, rank 1, score 0.90
2025-05-13 13:34:50,876 - INFO - Inserted recommendation for user 4a36fcf0-b382-412d-b95f-8075261a1b5c, car ca0206ce-79ba-467a-be32-62ee92ab8316, rank 2, score 0.90
2025-05-13 13:34:50,877 - INFO - Inserted recommendation for user 4a36fcf0-b382-412d-b95f-8075261a1b5c, car d7a936a2-deaa-44e5-8e73-aba1cfded7d0, rank 3, score 0.90
2025-05-13 13:34:50,877 - INFO - User 4a36fcf0-b382-412d-b95f-8075261a1b5c: Added 3 new recommendations
2025-05-13 13:34:50,878 - INFO - 
Sample recommendations in database:
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 21ff0142-15f6-4142-91eb-163478e9f020, Rank: 4, Score: 0.55, Reason: Matches your preferences for volkswagen brand, essence fuel, manuelle transmission
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 2f4688ff-eb97-4676-81cf-83835b9c4d19, Rank: 3, Score: 0.47, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.57)
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 531f113b-9318-4a12-9fba-94118c5c93b8, Rank: 1, Score: 0.69, Reason: Matches your preferences for volkswagen brand, 3 doors, diesel fuel, manuelle transmission
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 79ad63e7-311e-486d-ae2f-445b43777af2, Rank: 3, Score: 0.56, Reason: Matches your preferences for volkswagen brand, essence fuel, manuelle transmission
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 804cebfd-670c-47b1-b54a-20ff20d16200, Rank: 2, Score: 0.84, Reason: Based on your viewing - search and favorite patterns
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 8d348d2f-976b-41d1-9a7c-e5376b926e2d, Rank: 3, Score: 0.50, Reason: Random popular car
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: b4668121-d4bc-4e71-9048-11bafc750cd2, Rank: 2, Score: 0.50, Reason: Random popular car
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: b6d67f3c-a067-4e6b-ba14-ffa3bf46b010, Rank: 5, Score: 0.55, Reason: Matches your preferences for volkswagen brand, diesel fuel, manuelle transmission
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: bee3cea0-afc1-43e8-a92c-a71d25313745, Rank: 1, Score: 0.90, Reason: Based on your viewing - search and favorite patterns
2025-05-13 13:34:50,878 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: da987057-0d2f-4663-bfc3-7c78c2a8b686, Rank: 1, Score: 0.50, Reason: Random popular car
2025-05-13 13:34:50,882 - WARNING - Server warning: Aggregation query used without partition key
2025-05-13 13:34:50,882 - INFO - Total recommendations stored: 420
2025-05-13 13:34:50,882 - INFO - Recommendation process complete.
(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ ls
all.py  content_based_filtering.py  hybrid_recommendations.py  item_b_collab_filtering.py  user_b_collab_filtering.py
(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ cat user_b_collab_filtering.py
import pandas as pd
import numpy as np
from cassandra.cluster import Cluster, EXEC_PROFILE_DEFAULT, ExecutionProfile
from cassandra.query import SimpleStatement
from cassandra.policies import DCAwareRoundRobinPolicy
from datetime import datetime
from pytz import UTC
import pytz
import logging
import random
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
from scipy.sparse.linalg import svds
import uuid

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Connect to Cassandra
def setup_cassandra_session():
    try:
        profile = ExecutionProfile(load_balancing_policy=DCAwareRoundRobinPolicy(local_dc='datacenter1'))
        cluster = Cluster(['localhost'], execution_profiles={EXEC_PROFILE_DEFAULT: profile}, protocol_version=4)
        session = cluster.connect('cars_keyspace')
        logging.info("Connected to Cassandra")
        return session, cluster
    except Exception as e:
        logging.error(f"Error connecting to Cassandra: {e}")
        raise

# Recency weight function
def recency_weight(timestamp, current_time):
    try:
        if timestamp.tzinfo is None:
            timestamp = pytz.UTC.localize(timestamp)
        days_old = (current_time - timestamp).total_seconds() / (24 * 3600)
        return max(0.5, 1.0 - (days_old / 30.0))
    except Exception as e:
        logging.warning(f"Invalid timestamp {timestamp}: {e}")
        return 0.5

# Fetch data for a specific user
def fetch_data(session, user_id):
    try:
        user_id_uuid = uuid.UUID(user_id)

        # Fetch user views
        views_query = "SELECT user_id, car_id, view_timestamp FROM car_views_by_user WHERE user_id = %s"
        views_rows = session.execute(SimpleStatement(views_query), [user_id_uuid])
        views_data = [(str(row.user_id), str(row.car_id), row.view_timestamp) for row in views_rows]
        logging.info(f"Fetched {len(views_data)} view records for user {user_id}")

        # Fetch user favorites
        favs_query = "SELECT user_id, car_id, added_timestamp FROM favorite_cars_by_user WHERE user_id = %s"
        favs_rows = session.execute(SimpleStatement(favs_query), [user_id_uuid])
        favs_data = [(str(row.user_id), str(row.car_id), row.added_timestamp) for row in favs_rows]
        logging.info(f"Fetched {len(favs_data)} favorite records for user {user_id}")

        # Fetch user preferences
        prefs_query = """
            SELECT user_id, preferred_brands, preferred_door_count, preferred_fuel_types,
                   preferred_transmissions, budget_max, budget_min, mileage_max, mileage_min,
                   preferred_years FROM user_preferences WHERE user_id = %s
        """
        prefs_rows = session.execute(SimpleStatement(prefs_query), [user_id_uuid])
        prefs_data = [
            (
                str(row.user_id),
                row.preferred_brands or set(),
                row.preferred_door_count or set(),
                row.preferred_fuel_types or set(),
                row.preferred_transmissions or set(),
                row.budget_max or 0.0,
                row.budget_min or 0.0,
                row.mileage_max or 0.0,
                row.mileage_min or 0.0,
                row.preferred_years or set()
            ) for row in prefs_rows
        ]
        logging.info(f"Fetched {len(prefs_data)} preference records for user {user_id}")

        # Fetch all cars
        cars_query = """
            SELECT id, brand, door_count, fuel_type, transmission, price, mileage, year
            FROM cleaned_cars
        """
        cars_rows = session.execute(SimpleStatement(cars_query))
        cars_data = [
            (
                str(row.id),
                row.brand or 'unknown',
                row.door_count,
                row.fuel_type or 'unknown',
                row.transmission or 'unknown',
                row.price or np.nan,
                row.mileage or np.nan,
                row.year or np.nan
            ) for row in cars_rows
        ]
        logging.info(f"Fetched {len(cars_data)} car records")

        # Fetch all views and favorites for collaborative filtering
        all_views_query = "SELECT user_id, car_id, view_timestamp FROM car_views_by_user"
        all_views_rows = session.execute(SimpleStatement(all_views_query))
        all_views_data = [(str(row.user_id), str(row.car_id), row.view_timestamp) for row in all_views_rows]
        logging.info(f"Fetched {len(all_views_data)} view records for all users")

        all_favs_query = "SELECT user_id, car_id, added_timestamp FROM favorite_cars_by_user"
        all_favs_rows = session.execute(SimpleStatement(all_favs_query))
        all_favs_data = [(str(row.user_id), str(row.car_id), row.added_timestamp) for row in all_favs_rows]
        logging.info(f"Fetched {len(all_favs_data)} favorite records for all users")

        return views_data, favs_data, prefs_data, cars_data, all_views_data, all_favs_data
    except Exception as e:
        logging.error(f"Error fetching data: {e}")
        raise

# Delete existing recommendations
def delete_existing_recommendations(session, user_id):
    try:
        user_id_uuid = uuid.UUID(user_id)
        query = "DELETE FROM user_recommendations WHERE user_id = %s"
        session.execute(SimpleStatement(query), [user_id_uuid])
        logging.info(f"Deleted existing recommendations for user {user_id}")
    except Exception as e:
        logging.error(f"Error deleting recommendations for user {user_id}: {e}")
        raise

# Fetch fallback recommendations
def get_fallback_recommendations(session, excluded_car_ids=None):
    try:
        if excluded_car_ids is None:
            excluded_car_ids = set()
        query = "SELECT id FROM cleaned_cars LIMIT 10"
        rows = session.execute(SimpleStatement(query))
        car_ids = [str(row.id) for row in rows if str(row.id) not in excluded_car_ids]
        if not car_ids:
            logging.warning("No valid cars found for fallback after excluding {len(excluded_car_ids)} cars")
            return []
        random.shuffle(car_ids)
        return [(car_id, 0.5, "Random popular car") for car_id in car_ids[:3]]
    except Exception as e:
        logging.error(f"Error fetching fallback recommendations: {e}")
        return []

# User-based collaborative filtering
def user_based_collaborative_filtering(user_id, all_views_df, all_favs_df, current_time, session, excluded_car_ids=None):
    try:
        if excluded_car_ids is None:
            excluded_car_ids = set()
        interactions = []
        for _, row in all_views_df.iterrows():
            if pd.notnull(row['view_timestamp']):
                interactions.append((row['user_id'], row['car_id'], 1.0 * recency_weight(row['view_timestamp'], current_time)))
        for _, row in all_favs_df.iterrows():
            if pd.notnull(row['added_timestamp']):
                interactions.append((row['user_id'], row['car_id'], 2.0 * recency_weight(row['added_timestamp'], current_time)))

        interaction_df = pd.DataFrame(interactions, columns=['user_id', 'car_id', 'score'])
        user_item_matrix = pd.pivot_table(
            interaction_df, values='score', index='user_id', columns='car_id', aggfunc='sum', fill_value=0
        )

        logging.info(f"User-item matrix shape: {user_item_matrix.shape}, sparsity: {1 - (interaction_df.shape[0] / (user_item_matrix.shape[0] * user_item_matrix.shape[1])):.4f}")
        if user_id not in user_item_matrix.index:
            logging.warning(f"User {user_id} not in user_item_matrix, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        user_similarity_matrix = cosine_similarity(user_item_matrix)
        user_ids = user_item_matrix.index
        user_similarity_df = pd.DataFrame(user_similarity_matrix, index=user_ids, columns=user_ids)

        user_views = set(all_views_df[all_views_df['user_id'] == user_id]['car_id'])
        user_favs = set(all_favs_df[all_favs_df['user_id'] == user_id]['car_id'])
        all_favs = set(all_favs_df['car_id'])
        excluded_cars = user_views.union(user_favs).union(all_favs).union(excluded_car_ids)

        similar_users = user_similarity_df.loc[user_id].sort_values(ascending=False)[1:21]  # Increased to 20 for more candidates
        candidate_scores = {}
        for similar_user_id, sim_score in similar_users.items():
            if sim_score > 0.1:  # Lowered threshold
                similar_user_views = set(all_views_df[all_views_df['user_id'] == similar_user_id]['car_id'])
                similar_user_favs = set(all_favs_df[all_favs_df['user_id'] == similar_user_id]['car_id'])
                similar_user_cars = similar_user_views.union(similar_user_favs)
                for car_id in similar_user_cars:
                    if car_id not in excluded_cars:
                        candidate_scores[car_id] = candidate_scores.get(car_id, 0) + sim_score

        if candidate_scores:
            max_score = max(candidate_scores.values())
            candidate_scores = {car_id: (score / max_score) * 0.9 for car_id, score in candidate_scores.items()}
            logging.info(f"User-based generated {len(candidate_scores)} candidates for {user_id}")
        else:
            logging.warning(f"No similar user recommendations for {user_id}, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        top_recs = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)[:3]
        return [(car_id, score, "Based on similarities with another user") for car_id, score in top_recs]
    except Exception as e:
        logging.error(f"Error in user-based collaborative filtering: {e}")
        return get_fallback_recommendations(session, excluded_car_ids)

# Item-based collaborative filtering
def item_based_collaborative_filtering(user_id, all_views_df, all_favs_df, current_time, session, excluded_car_ids=None):
    try:
        if excluded_car_ids is None:
            excluded_car_ids = set()
        interactions = []
        for _, row in all_views_df.iterrows():
            if pd.notnull(row['view_timestamp']):
                interactions.append((row['user_id'], row['car_id'], 1.0 * recency_weight(row['view_timestamp'], current_time)))
        for _, row in all_favs_df.iterrows():
            if pd.notnull(row['added_timestamp']):
                interactions.append((row['user_id'], row['car_id'], 2.0 * recency_weight(row['added_timestamp'], current_time)))

        interaction_df = pd.DataFrame(interactions, columns=['user_id', 'car_id', 'score'])
        user_item_matrix = pd.pivot_table(
            interaction_df, values='score', index='user_id', columns='car_id', aggfunc='sum', fill_value=0
        )

        logging.info(f"User-item matrix shape: {user_item_matrix.shape}, sparsity: {1 - (interaction_df.shape[0] / (user_item_matrix.shape[0] * user_item_matrix.shape[1])):.4f}")
        car_similarity_matrix = cosine_similarity(user_item_matrix.T)
        car_ids = user_item_matrix.columns
        car_similarity_df = pd.DataFrame(car_similarity_matrix, index=car_ids, columns=car_ids)

        user_views = set(all_views_df[all_views_df['user_id'] == user_id]['car_id'])
        user_favs = set(all_favs_df[all_favs_df['user_id'] == user_id]['car_id'])
        all_favs = set(all_favs_df['car_id'])
        user_interactions = user_views.union(user_favs).union(all_favs).union(excluded_car_ids)

        if not user_interactions:
            logging.warning(f"No interactions for {user_id}, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        candidate_scores = {}
        for car_id in user_interactions:
            if car_id in car_similarity_df.index:
                similar_cars = car_similarity_df.loc[car_id].dropna()
                for similar_car_id, sim_score in similar_cars.items():
                    if similar_car_id not in user_interactions and sim_score > 0.1:  # Lowered threshold
                        candidate_scores[similar_car_id] = candidate_scores.get(similar_car_id, 0) + sim_score

        if candidate_scores:
            max_score = max(candidate_scores.values())
            candidate_scores = {car_id: (score / max_score) * 0.9 for car_id, score in candidate_scores.items()}
            logging.info(f"Item-based generated {len(candidate_scores)} candidates for {user_id}")
        else:
            logging.warning(f"No similar item recommendations for {user_id}, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        top_recs = sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)[:3]
        return [(car_id, score, "Based on your viewing - search and favorite patterns") for car_id, score in top_recs]
    except Exception as e:
        logging.error(f"Error in item-based collaborative filtering: {e}")
        return get_fallback_recommendations(session, excluded_car_ids)

# Content-based filtering
def content_based_filtering(user_id, user_prefs_df, cars_df, session, excluded_car_ids=None):
    try:
        if excluded_car_ids is None:
            excluded_car_ids = set()
        if user_prefs_df.empty:
            logging.warning(f"No preferences for {user_id}, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        user_prefs_df['preferred_transmissions'] = user_prefs_df['preferred_transmissions'].apply(lambda x: {t.lower() for t in x})
        cars_df['transmission'] = cars_df['transmission'].str.lower()
        cars_df['brand'] = cars_df['brand'].str.lower()
        cars_df['fuel_type'] = cars_df['fuel_type'].str.lower()

        cars_df['door_count'] = cars_df['door_count'].fillna(5).astype(int)
        cars_df['price'] = cars_df['price'].fillna(cars_df['price'].median(skipna=True))
        cars_df['mileage'] = cars_df['mileage'].fillna(cars_df['mileage'].median(skipna=True))
        cars_df['year'] = cars_df['year'].fillna(cars_df['year'].median(skipna=True))

        all_brands = sorted(set(cars_df['brand'].unique()) | set().union(*user_prefs_df['preferred_brands']))
        door_counts = sorted(set(cars_df['door_count'].unique()) | set().union(*user_prefs_df['preferred_door_count']))
        all_fuel_types = sorted(set(cars_df['fuel_type'].unique()) | set().union(*user_prefs_df['preferred_fuel_types']))
        all_transmissions = sorted(set(cars_df['transmission'].unique()) | set().union(*user_prefs_df['preferred_transmissions']))

        numerical_cols = ['budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years_mean', 'price', 'mileage', 'year']
        categorical_cols = (
            [f'brand_{b}' for b in all_brands] +
            [f'door_count_{dc}' for dc in door_counts] +
            [f'fuel_type_{ft}' for ft in all_fuel_types] +
            [f'transmission_{tr}' for tr in all_transmissions]
        )

        user_prefs_df['preferred_years_mean'] = user_prefs_df['preferred_years'].apply(lambda x: np.mean(list(x)) if x else 2018)
        user_num_values = MinMaxScaler().fit_transform(
            user_prefs_df[['budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years_mean']]
        )
        user_num_df = pd.DataFrame(0.0, index=user_prefs_df['user_id'], columns=numerical_cols)
        user_num_df[['budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years_mean']] = user_num_values

        car_num_values = MinMaxScaler().fit_transform(cars_df[['price', 'mileage', 'year']])
        car_num_df = pd.DataFrame(0.0, index=cars_df['car_id'], columns=numerical_cols)
        car_num_df[['price', 'mileage', 'year']] = car_num_values

        user_cat_data = {col: np.zeros(len(user_prefs_df)) for col in categorical_cols}
        for i, row in user_prefs_df.iterrows():
            for brand in row['preferred_brands']:
                if brand in all_brands:
                    user_cat_data[f'brand_{brand}'][i] = 1
            for dc in row['preferred_door_count']:
                if dc in door_counts:
                    user_cat_data[f'door_count_{dc}'][i] = 1
            for ft in row['preferred_fuel_types']:
                if ft in all_fuel_types:
                    user_cat_data[f'fuel_type_{ft}'][i] = 1
            for tr in row['preferred_transmissions']:
                if tr in all_transmissions:
                    user_cat_data[f'transmission_{tr}'][i] = 1
        user_cat_df = pd.DataFrame(user_cat_data, index=user_prefs_df['user_id'])

        car_cat_data = {col: np.zeros(len(cars_df)) for col in categorical_cols}
        for i, row in cars_df.iterrows():
            if row['brand'] in all_brands:
                car_cat_data[f'brand_{row["brand"]}'][i] = 1
            if row['door_count'] in door_counts:
                car_cat_data[f'door_count_{row["door_count"]}'][i] = 1
            if row['fuel_type'] in all_fuel_types:
                car_cat_data[f'fuel_type_{row["fuel_type"]}'][i] = 1
            if row['transmission'] in all_transmissions:
                car_cat_data[f'transmission_{row["transmission"]}'][i] = 1
        car_cat_df = pd.DataFrame(car_cat_data, index=cars_df['car_id'])

        user_features_df = pd.concat([user_cat_df, user_num_df], axis=1)
        car_features_df = pd.concat([car_cat_df, car_num_df], axis=1)

        similarity_matrix = cosine_similarity(user_features_df.values, car_features_df.values)
        similarity_df = pd.DataFrame(similarity_matrix, index=user_features_df.index, columns=car_features_df.index)

        user_similarities = similarity_df.loc[user_id]
        user_similarities = user_similarities.drop(list(excluded_car_ids), errors='ignore')
        top_cars = user_similarities.nlargest(3)
        recommendations = []
        for car_id, score in top_cars.items():
            user_features = user_features_df.loc[user_id]
            car_features = car_features_df.loc[car_id]
            matches = []
            for col in user_features.index:
                if col.startswith('brand_') and user_features[col] > 0 and car_features[col] > 0:
                    matches.append(f"{col.replace('brand_', '')} brand")
                elif col.startswith('fuel_type_') and user_features[col] > 0 and car_features[col] > 0:
                    matches.append(f"{col.replace('fuel_type_', '')} fuel")
                elif col.startswith('transmission_') and user_features[col] > 0 and car_features[col] > 0:
                    matches.append(f"{col.replace('transmission_', '')} transmission")
                elif col.startswith('door_count_') and user_features[col] > 0 and car_features[col] > 0:
                    matches.append(f"{col.replace('door_count_', '')} doors")
            reason = f"Matches your preferences for {', '.join(matches) if matches else 'similar features'}"
            recommendations.append((car_id, score, reason))

        if not recommendations:
            logging.warning(f"No content-based recommendations for {user_id}, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        return recommendations
    except Exception as e:
        logging.error(f"Error in content-based filtering: {e}")
        return get_fallback_recommendations(session, excluded_car_ids)

# Hybrid recommendations
def hybrid_recommendations(user_id, all_views_df, all_favs_df, user_prefs_df, cars_df, current_time, session, excluded_car_ids=None):
    try:
        if excluded_car_ids is None:
            excluded_car_ids = set()
        interactions = []
        for _, row in all_views_df.iterrows():
            if pd.notnull(row['view_timestamp']):
                interactions.append((row['user_id'], row['car_id'], 0.5 * recency_weight(row['view_timestamp'], current_time)))
        for _, row in all_favs_df.iterrows():
            if pd.notnull(row['added_timestamp']):
                interactions.append((row['user_id'], row['car_id'], 1.0 * recency_weight(row['added_timestamp'], current_time)))

        interaction_df = pd.DataFrame(interactions, columns=['user_id', 'car_id', 'rating'])
        user_item_matrix = pd.pivot_table(
            interaction_df, values='rating', index='user_id', columns='car_id', aggfunc='max', fill_value=0
        )

        logging.info(f"User-item matrix shape: {user_item_matrix.shape}, sparsity: {1 - (interaction_df.shape[0] / (user_item_matrix.shape[0] * user_item_matrix.shape[1])):.4f}")
        if user_id not in user_item_matrix.index:
            logging.warning(f"No interactions for {user_id} in hybrid, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        R = user_item_matrix.values
        min_dim = min(R.shape)
        if min_dim <= 1:
            logging.warning(f"User-item matrix too small for SVD (shape: {R.shape}), using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        k = min(20, min_dim - 1)
        U, sigma, Vt = svds(R, k=k)
        sigma = np.diag(sigma)
        R_pred = np.dot(np.dot(U, sigma), Vt)
        R_pred[R_pred < 0] = 0
        pred_df = pd.DataFrame(R_pred, index=user_item_matrix.index, columns=user_item_matrix.columns)

        if user_prefs_df.empty:
            logging.warning(f"No preferences for {user_id} in hybrid, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        user_prefs_df['preferred_transmissions'] = user_prefs_df['preferred_transmissions'].apply(lambda x: {t.lower() for t in x})
        cars_df['transmission'] = cars_df['transmission'].str.lower()
        cars_df['brand'] = cars_df['brand'].str.lower()
        cars_df['fuel_type'] = cars_df['fuel_type'].str.lower()

        cars_df['door_count'] = cars_df['door_count'].fillna(5).astype(int)
        cars_df['price'] = cars_df['price'].fillna(cars_df['price'].median(skipna=True))
        cars_df['mileage'] = cars_df['mileage'].fillna(cars_df['mileage'].median(skipna=True))
        cars_df['year'] = cars_df['year'].fillna(cars_df['year'].median(skipna=True))

        all_brands = sorted(set(cars_df['brand'].unique()) | set().union(*user_prefs_df['preferred_brands']))
        door_counts = sorted(set(cars_df['door_count'].unique()) | set().union(*user_prefs_df['preferred_door_count']))
        all_fuel_types = sorted(set(cars_df['fuel_type'].unique()) | set().union(*user_prefs_df['preferred_fuel_types']))
        all_transmissions = sorted(set(cars_df['transmission'].unique()) | set().union(*user_prefs_df['preferred_transmissions']))

        numerical_cols = ['budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years_mean', 'price', 'mileage', 'year']
        categorical_cols = (
            [f'brand_{b}' for b in all_brands] +
            [f'door_count_{dc}' for dc in door_counts] +
            [f'fuel_type_{ft}' for ft in all_fuel_types] +
            [f'transmission_{tr}' for tr in all_transmissions]
        )

        user_prefs_df['preferred_years_mean'] = user_prefs_df['preferred_years'].apply(lambda x: np.mean(list(x)) if x else 2018)
        user_num_values = MinMaxScaler().fit_transform(
            user_prefs_df[['budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years_mean']]
        )
        user_num_df = pd.DataFrame(0.0, index=user_prefs_df['user_id'], columns=numerical_cols)
        user_num_df[['budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years_mean']] = user_num_values

        car_num_values = MinMaxScaler().fit_transform(cars_df[['price', 'mileage', 'year']])
        car_num_df = pd.DataFrame(0.0, index=cars_df['car_id'], columns=numerical_cols)
        car_num_df[['price', 'mileage', 'year']] = car_num_values

        user_cat_data = {col: np.zeros(len(user_prefs_df)) for col in categorical_cols}
        for i, row in user_prefs_df.iterrows():
            for brand in row['preferred_brands']:
                if brand in all_brands:
                    user_cat_data[f'brand_{brand}'][i] = 1
            for dc in row['preferred_door_count']:
                if dc in door_counts:
                    user_cat_data[f'door_count_{dc}'][i] = 1
            for ft in row['preferred_fuel_types']:
                if ft in all_fuel_types:
                    user_cat_data[f'fuel_type_{ft}'][i] = 1
            for tr in row['preferred_transmissions']:
                if tr in all_transmissions:
                    user_cat_data[f'transmission_{tr}'][i] = 1
        user_cat_df = pd.DataFrame(user_cat_data, index=user_prefs_df['user_id'])

        car_cat_data = {col: np.zeros(len(cars_df)) for col in categorical_cols}
        for i, row in cars_df.iterrows():
            if row['brand'] in all_brands:
                car_cat_data[f'brand_{row["brand"]}'][i] = 1
            if row['door_count'] in door_counts:
                car_cat_data[f'door_count_{row["door_count"]}'][i] = 1
            if row['fuel_type'] in all_fuel_types:
                car_cat_data[f'fuel_type_{row["fuel_type"]}'][i] = 1
            if row['transmission'] in all_transmissions:
                car_cat_data[f'transmission_{row["transmission"]}'][i] = 1
        car_cat_df = pd.DataFrame(car_cat_data, index=cars_df['car_id'])

        user_features_df = pd.concat([user_cat_df, user_num_df], axis=1)
        car_features_df = pd.concat([car_cat_df, car_num_df], axis=1)

        content_similarity_matrix = cosine_similarity(user_features_df.values, car_features_df.values)
        content_similarity_df = pd.DataFrame(content_similarity_matrix, index=user_features_df.index, columns=car_features_df.index)

        # Align columns between collaborative and content-based scores
        common_cars = pred_df.columns.intersection(content_similarity_df.columns)
        if not common_cars.empty:
            collab_scores = MinMaxScaler().fit_transform(pred_df.loc[[user_id], common_cars].values.reshape(-1, 1)).reshape(1, -1)
            content_scores = MinMaxScaler().fit_transform(content_similarity_df.loc[[user_id], common_cars].values.reshape(-1, 1)).reshape(1, -1)

            alpha = 0.5
            hybrid_scores = alpha * collab_scores + (1 - alpha) * content_scores
            hybrid_df = pd.DataFrame(hybrid_scores, index=[user_id], columns=common_cars)
        else:
            logging.warning(f"No common cars between collaborative and content-based data for {user_id}, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        user_views = set(all_views_df[all_views_df['user_id'] == user_id]['car_id'])
        user_favs = set(all_favs_df[all_favs_df['user_id'] == user_id]['car_id'])
        all_favs = set(all_favs_df['car_id'])
        unrated_cars = [col for col in hybrid_df.columns if col not in user_views.union(user_favs).union(all_favs).union(excluded_car_ids)]
        top_cars = hybrid_df.loc[user_id, unrated_cars].nlargest(3).index
        top_scores = hybrid_df.loc[user_id, top_cars].values

        recommendations = []
        for car_id, score in zip(top_cars, top_scores):
            collab_score = pred_df.loc[user_id, car_id] if car_id in pred_df.columns else 0.0
            content_score = content_similarity_df.loc[user_id, car_id] if car_id in content_similarity_df.columns else 0.0
            reason = f"Hybrid: {alpha:.2f}*collaborative ({collab_score:.2f}) + {1-alpha:.2f}*content-based ({content_score:.2f})"
            recommendations.append((car_id, score, reason))

        if not recommendations:
            logging.warning(f"No hybrid recommendations for {user_id}, using fallback")
            return get_fallback_recommendations(session, excluded_car_ids)

        return recommendations
    except Exception as e:
        logging.error(f"Error in hybrid recommendations: {e}")
        return get_fallback_recommendations(session, excluded_car_ids)

# Main function
def generate_recommendations(user_id):
    session, cluster = setup_cassandra_session()
    try:
        # Fetch data
        views_data, favs_data, prefs_data, cars_data, all_views_data, all_favs_data = fetch_data(session, user_id)
        views_df = pd.DataFrame(views_data, columns=['user_id', 'car_id', 'view_timestamp'])
        favs_df = pd.DataFrame(favs_data, columns=['user_id', 'car_id', 'added_timestamp'])
        all_views_df = pd.DataFrame(all_views_data, columns=['user_id', 'car_id', 'view_timestamp'])
        all_favs_df = pd.DataFrame(all_favs_data, columns=['user_id', 'car_id', 'added_timestamp'])
        user_prefs_df = pd.DataFrame(
            prefs_data,
            columns=['user_id', 'preferred_brands', 'preferred_door_count', 'preferred_fuel_types',
                     'preferred_transmissions', 'budget_max', 'budget_min', 'mileage_max', 'mileage_min', 'preferred_years']
        )
        cars_df = pd.DataFrame(
            cars_data,
            columns=['car_id', 'brand', 'door_count', 'fuel_type', 'transmission', 'price', 'mileage', 'year']
        )

        # Delete existing recommendations
        delete_existing_recommendations(session, user_id)

        current_time = datetime.now(UTC)

        # Initialize excluded car IDs with user's views and favorites
        user_views = set(views_df['car_id'])
        user_favs = set(favs_df['car_id'])
        all_favs = set(all_favs_df['car_id'])
        used_car_ids = user_views.union(user_favs).union(all_favs)

        # Generate recommendations
        user_based_recs = user_based_collaborative_filtering(user_id, all_views_df, all_favs_df, current_time, session, used_car_ids)
        used_car_ids.update([car_id for car_id, _, _ in user_based_recs])

        item_based_recs = item_based_collaborative_filtering(user_id, all_views_df, all_favs_df, current_time, session, used_car_ids)
        used_car_ids.update([car_id for car_id, _, _ in item_based_recs])

        content_based_recs = content_based_filtering(user_id, user_prefs_df, cars_df, session, used_car_ids)
        used_car_ids.update([car_id for car_id, _, _ in content_based_recs])

        hybrid_recs = hybrid_recommendations(user_id, all_views_df, all_favs_df, user_prefs_df, cars_df, current_time, session, used_car_ids)
        used_car_ids.update([car_id for car_id, _, _ in hybrid_recs])

        # Combine recommendations
        all_recommendations = []
        methods = [
            (user_based_recs, "user-based"),
            (item_based_recs, "item-based"),
            (content_based_recs, "content-based"),
            (hybrid_recs, "hybrid")
        ]

        for recs, method in methods:
            for i, (car_id, score, reason) in enumerate(recs, 1):
                all_recommendations.append({
                    'user_id': uuid.UUID(user_id),
                    'car_id': uuid.UUID(car_id),
                    'rank': i,
                    'similarity_score': float(score),
                    'recommendation_reason': reason,
                    'created_at': current_time,
                    'method': method
                })

        # Insert recommendations
        insert_query = """
            INSERT INTO user_recommendations (user_id, car_id, created_at, rank, recommendation_reason, similarity_score)
            VALUES (%s, %s, %s, %s, %s, %s)
        """
        for rec in all_recommendations:
            try:
                session.execute(
                    insert_query,
                    (
                        rec['user_id'],
                        rec['car_id'],
                        rec['created_at'],
                        rec['rank'],
                        rec['recommendation_reason'],
                        rec['similarity_score']
                    )
                )
            except Exception as e:
                logging.error(f"Error inserting recommendation for user {rec['user_id']}, car {rec['car_id']}: {e}")

        logging.info(f"Inserted {len(all_recommendations)} recommendations for user {user_id}")

        # Verify insertion
        rows = session.execute(
            "SELECT user_id, car_id, rank, similarity_score, recommendation_reason FROM user_recommendations WHERE user_id = %s",
            [uuid.UUID(user_id)]
        )
        logging.info(f"\nRecommendations for user {user_id} in database:")
        for row in rows:
            logging.info(f"Car: {row.car_id}, Rank: {row.rank}, Score: {row.similarity_score:.2f}, Reason: {row.recommendation_reason}")

    except Exception as e:
        logging.error(f"Error in recommendation process: {e}")
    finally:
        cluster.shutdown()

if __name__ == "__main__":
    import sys
    if len(sys.argv) != 2:
        logging.error("Usage: python user_b_collab_filtering.py <user_id>")
        sys.exit(1)
    generate_recommendations(sys.argv[1])(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ python user_b_collab_filtering.py 588f2dc3-c048-4c61-a241-3bcd654a4404
2025-05-13 13:35:12,907 - INFO - Connected to Cassandra
2025-05-13 13:35:12,909 - INFO - Fetched 2 view records for user 588f2dc3-c048-4c61-a241-3bcd654a4404
2025-05-13 13:35:12,911 - INFO - Fetched 1 favorite records for user 588f2dc3-c048-4c61-a241-3bcd654a4404
2025-05-13 13:35:12,912 - INFO - Fetched 1 preference records for user 588f2dc3-c048-4c61-a241-3bcd654a4404
2025-05-13 13:35:12,926 - WARNING - Server warning: Read 633 live rows and 1472 tombstone cells for query SELECT brand, door_count, fuel_type, mileage, price, transmission, year FROM cars_keyspace.cleaned_cars LIMIT 5000 ALLOW FILTERING; token 9207834739780070790 (see tombstone_warn_threshold)
2025-05-13 13:35:12,928 - INFO - Fetched 633 car records
2025-05-13 13:35:12,932 - INFO - Fetched 157 view records for all users
2025-05-13 13:35:12,935 - INFO - Fetched 109 favorite records for all users
2025-05-13 13:35:12,940 - INFO - Deleted existing recommendations for user 588f2dc3-c048-4c61-a241-3bcd654a4404
2025-05-13 13:35:12,994 - INFO - User-item matrix shape: (53, 191), sparsity: 0.9737
2025-05-13 13:35:13,002 - WARNING - No similar user recommendations for 588f2dc3-c048-4c61-a241-3bcd654a4404, using fallback
2025-05-13 13:35:13,066 - INFO - User-item matrix shape: (53, 191), sparsity: 0.9737
2025-05-13 13:35:13,080 - INFO - Item-based generated 108 candidates for 588f2dc3-c048-4c61-a241-3bcd654a4404
2025-05-13 13:35:13,177 - INFO - User-item matrix shape: (53, 191), sparsity: 0.9737
2025-05-13 13:35:13,238 - INFO - Inserted 12 recommendations for user 588f2dc3-c048-4c61-a241-3bcd654a4404
2025-05-13 13:35:13,239 - INFO - 
Recommendations for user 588f2dc3-c048-4c61-a241-3bcd654a4404 in database:
2025-05-13 13:35:13,239 - INFO - Car: 21ff0142-15f6-4142-91eb-163478e9f020, Rank: 1, Score: 0.50, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.60)
2025-05-13 13:35:13,240 - INFO - Car: 2f4688ff-eb97-4676-81cf-83835b9c4d19, Rank: 3, Score: 0.47, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.57)
2025-05-13 13:35:13,240 - INFO - Car: 43ad7c74-3624-42e0-b47b-b698d03cccd6, Rank: 3, Score: 0.50, Reason: Random popular car
2025-05-13 13:35:13,240 - INFO - Car: 531f113b-9318-4a12-9fba-94118c5c93b8, Rank: 1, Score: 0.75, Reason: Matches your preferences for volkswagen brand, 3 doors, diesel fuel, manuelle transmission
2025-05-13 13:35:13,240 - INFO - Car: 79ad63e7-311e-486d-ae2f-445b43777af2, Rank: 3, Score: 0.61, Reason: Matches your preferences for volkswagen brand, essence fuel, manuelle transmission
2025-05-13 13:35:13,240 - INFO - Car: 804cebfd-670c-47b1-b54a-20ff20d16200, Rank: 2, Score: 0.84, Reason: Based on your viewing - search and favorite patterns
2025-05-13 13:35:13,240 - INFO - Car: 8d348d2f-976b-41d1-9a7c-e5376b926e2d, Rank: 2, Score: 0.50, Reason: Random popular car
2025-05-13 13:35:13,240 - INFO - Car: b4668121-d4bc-4e71-9048-11bafc750cd2, Rank: 1, Score: 0.50, Reason: Random popular car
2025-05-13 13:35:13,240 - INFO - Car: bee3cea0-afc1-43e8-a92c-a71d25313745, Rank: 1, Score: 0.90, Reason: Based on your viewing - search and favorite patterns
2025-05-13 13:35:13,240 - INFO - Car: ddd9b770-817d-40cb-993f-d3366dea8dcb, Rank: 2, Score: 0.61, Reason: Matches your preferences for 3 doors, essence fuel, manuelle transmission
2025-05-13 13:35:13,240 - INFO - Car: e930825c-96cb-47e1-84c5-0fae9eaa825e, Rank: 3, Score: 0.77, Reason: Based on your viewing - search and favorite patterns
2025-05-13 13:35:13,240 - INFO - Car: ed0303d3-c4cb-4fcc-900e-2548749fd328, Rank: 2, Score: 0.47, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.57)
(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ ls
all.py  content_based_filtering.py  hybrid_recommendations.py  item_b_collab_filtering.py  user_b_collab_filtering.py
(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ cat hybrid_recommendations.py
import logging
import uuid
from datetime import datetime
import pytz
import numpy as np
import pandas as pd
from scipy.sparse.linalg import svds
from sklearn.preprocessing import MinMaxScaler
from cassandra.cluster import Cluster
from cassandra.policies import DCAwareRoundRobinPolicy
from cassandra.query import SimpleStatement
from cassandra import ConsistencyLevel
from cassandra.cluster import ExecutionProfile, EXEC_PROFILE_DEFAULT

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def setup_cassandra_session():
    """Initialize Cassandra cluster and session with execution profiles."""
    try:
        profile = ExecutionProfile(
            load_balancing_policy=DCAwareRoundRobinPolicy(local_dc='datacenter1'),
            consistency_level=ConsistencyLevel.LOCAL_QUORUM
        )
        cluster = Cluster(
            contact_points=['localhost'],
            execution_profiles={EXEC_PROFILE_DEFAULT: profile},
            protocol_version=4
        )
        session = cluster.connect('cars_keyspace')
        logging.info("Connected to Cassandra cluster")
        return session, cluster
    except Exception as e:
        logging.error(f"Failed to connect to Cassandra: {e}")
        raise

def validate_timestamp(timestamp):
    """Validate and normalize timestamp, returning a weight based on recency."""
    default_weight = 0.5
    if not isinstance(timestamp, datetime):
        logging.warning(f"Invalid timestamp {timestamp}: not a datetime object, using default weight {default_weight}")
        return default_weight
    try:
        if timestamp.tzinfo is None:
            timestamp = pytz.utc.localize(timestamp)
        now = datetime.now(pytz.utc)
        days_old = (now - timestamp).days
        weight = max(0.1, 1.0 - (days_old / 30.0))
        return weight
    except Exception as e:
        logging.warning(f"Invalid timestamp {timestamp}: {e}, using default weight {default_weight}")
        return default_weight

def check_table_exists(session, table_name):
    """Check if a table exists in the keyspace."""
    query = f"SELECT table_name FROM system_schema.tables WHERE keyspace_name = 'cars_keyspace' AND table_name = '{table_name}'"
    rows = session.execute(SimpleStatement(query))
    return len(list(rows)) > 0

def fetch_data(session):
    """Fetch data from Cassandra tables, handling missing tables."""
    table_configs = {
        'car_views_by_user': {
            'query': "SELECT user_id, car_id, view_timestamp FROM car_views_by_user",
            'required': True
        },
        'favorite_cars_by_user': {
            'query': "SELECT user_id, car_id, added_timestamp FROM favorite_cars_by_user",
            'required': True
        },
        'user_preferences': {
            'query': "SELECT user_id, preferred_fuel_types, preferred_transmissions, preferred_door_count FROM user_preferences",
            'required': True
        },
        'cleaned_cars': {
            'query': "SELECT id, fuel_type, transmission, door_count, brand FROM cleaned_cars",
            'required': True
        },
        'user_similarities': {
            'query': "SELECT target_user_id, reference_user_id, similarity_score FROM user_similarities",
            'required': False
        }
    }
    data = {}
    for table, config in table_configs.items():
        if not check_table_exists(session, table):
            if config['required']:
                raise ValueError(f"Required table '{table}' does not exist in keyspace 'cars_keyspace'")
            else:
                logging.warning(f"Table '{table}' does not exist, skipping")
                data[table] = []
                continue
        try:
            rows = session.execute(SimpleStatement(config['query']))
            data[table] = list(rows)
            logging.info(f"{table.capitalize()} rows: {len(data[table])}, "
                         f"Unique users: {len(set(row.user_id for row in data[table] if hasattr(row, 'user_id') or hasattr(row, 'target_user_id')))}, "
                         f"Unique cars: {len(set(row.car_id for row in data[table] if hasattr(row, 'car_id')))}")
        except Exception as e:
            if config['required']:
                raise ValueError(f"Failed to query table '{table}': {e}")
            else:
                logging.warning(f"Failed to query table '{table}': {e}, skipping")
                data[table] = []
    return data

def build_user_item_matrix(views, favorites):
    """Build user-item interaction matrix from views and favorites."""
    interactions = []
    for view in views:
        interactions.append({
            'user_id': str(view.user_id),
            'car_id': str(view.car_id),
            'rating': validate_timestamp(view.view_timestamp) * 0.5  # Views weighted lower
        })
    for fav in favorites:
        interactions.append({
            'user_id': str(fav.user_id),
            'car_id': str(fav.car_id),
            'rating': validate_timestamp(fav.added_timestamp) * 1.0  # Favorites weighted higher
        })
    
    df = pd.DataFrame(interactions)
    user_item_matrix = df.pivot_table(index='user_id', columns='car_id', values='rating', aggfunc='max', fill_value=0)
    logging.info(f"User-item matrix shape: {user_item_matrix.shape}")
    return user_item_matrix

def compute_svd_predictions(user_item_matrix, k=20):
    """Apply SVD to predict collaborative filtering scores."""
    R = user_item_matrix.values
    U, sigma, Vt = svds(R, k=k)
    sigma = np.diag(sigma)
    R_pred = np.dot(np.dot(U, sigma), Vt)
    R_pred[R_pred < 0] = 0
    pred_df = pd.DataFrame(R_pred, index=user_item_matrix.index, columns=user_item_matrix.columns)
    logging.info(f"SVD predictions shape: {pred_df.shape}")
    return pred_df

def compute_content_similarity(user_prefs, cars):
    """Compute content-based similarity between user preferences and cars."""
    user_to_idx = {str(p.user_id): i for i, p in enumerate(user_prefs)}
    car_to_idx = {str(c.id): i for i, c in enumerate(cars)}
    similarity_matrix = np.zeros((len(user_prefs), len(cars)))
    
    for pref in user_prefs:
        u_idx = user_to_idx[str(pref.user_id)]
        for car in cars:
            c_idx = car_to_idx[str(car.id)]
            score = 0.0
            if pref.preferred_fuel_types and car.fuel_type in pref.preferred_fuel_types:
                score += 0.4
            if pref.preferred_transmissions and car.transmission in pref.preferred_transmissions:
                score += 0.3
            if pref.preferred_door_count and car.door_count in pref.preferred_door_count:
                score += 0.2
            similarity_matrix[u_idx, c_idx] = score
    
    similarity_df = pd.DataFrame(similarity_matrix, index=[str(p.user_id) for p in user_prefs], columns=[str(c.id) for c in cars])
    logging.info(f"Content-based similarity shape: {similarity_df.shape}")
    return similarity_df

def generate_recommendations(session, data):
    """Generate hybrid recommendations using SVD and content-based filtering."""
    # Build user-item matrix
    user_item_matrix = build_user_item_matrix(data['car_views_by_user'], data['favorite_cars_by_user'])
    
    # Compute SVD predictions
    pred_df = compute_svd_predictions(user_item_matrix)
    
    # Compute content-based similarity
    similarity_df = compute_content_similarity(data['user_preferences'], data['cleaned_cars'])
    
    # Align indices and columns
    common_users = pred_df.index.intersection(similarity_df.index).intersection(user_item_matrix.index)
    common_cars = pred_df.columns.intersection(similarity_df.columns).intersection(user_item_matrix.columns)
    if not common_users.size or not common_cars.size:
        logging.error("No common users or cars for recommendations")
        return []
    
    pred_df = pred_df.loc[common_users, common_cars]
    similarity_df = similarity_df.loc[common_users, common_cars]
    user_item_df = user_item_matrix.loc[common_users, common_cars]
    
    # Normalize scores
    collab_scores = MinMaxScaler().fit_transform(pred_df.values.reshape(-1, 1)).reshape(pred_df.shape)
    content_scores = MinMaxScaler().fit_transform(similarity_df.values.reshape(-1, 1)).reshape(similarity_df.shape)
    
    # Combine scores
    alpha = 0.5
    hybrid_scores = alpha * collab_scores + (1 - alpha) * content_scores
    hybrid_df = pd.DataFrame(hybrid_scores, index=common_users, columns=common_cars)
    logging.info(f"Hybrid scores shape: {hybrid_df.shape}")
    
    # Generate recommendations
    recommendations = []
    for user_id in hybrid_df.index:
        unrated_cars = user_item_df.loc[user_id][user_item_df.loc[user_id] == 0].index
        top_cars = hybrid_df.loc[user_id, unrated_cars].nlargest(5).index
        top_scores = hybrid_df.loc[user_id, top_cars].values
        
        for rank, (car_id, score) in enumerate(zip(top_cars, top_scores), 1):
            collab_score = pred_df.loc[user_id, car_id]
            content_score = similarity_df.loc[user_id, car_id]
            reason = f"Hybrid: {alpha:.2f}*collaborative ({collab_score:.2f}) + {1-alpha:.2f}*content-based ({content_score:.2f})"
            recommendations.append({
                'user_id': user_id,
                'car_id': car_id,
                'rank': rank,
                'reason': reason,
                'score': float(score),
                'created_at': datetime.now(pytz.utc)
            })
    
    logging.info(f"Total recommendations generated: {len(recommendations)}")
    return recommendations

def store_recommendations(session, recommendations):
    """Store recommendations in Cassandra user_recommendations table."""
    insert_query = """
        INSERT INTO user_recommendations (user_id, car_id, created_at, rank, recommendation_reason, similarity_score)
        VALUES (?, ?, ?, ?, ?, ?)
    """
    prepared = session.prepare(insert_query)
    for rec in recommendations:
        user_id = rec['user_id'] if isinstance(rec['user_id'], uuid.UUID) else uuid.UUID(rec['user_id'])
        car_id = rec['car_id'] if isinstance(rec['car_id'], uuid.UUID) else uuid.UUID(rec['car_id'])
        session.execute(prepared, (
            user_id,
            car_id,
            rec['created_at'],
            rec['rank'],
            rec['reason'],
            rec['score']
        ))
    logging.info(f"Total recommendations stored: {len(recommendations)}")
    
    sample_query = "SELECT user_id, car_id, rank, recommendation_reason, similarity_score FROM user_recommendations LIMIT 5"
    rows = session.execute(SimpleStatement(sample_query))
    logging.info("Sample recommendations from database:")
    for row in rows:
        logging.info(f"User: {row.user_id}, Car: {row.car_id}, Rank: {row.rank}, "
                     f"Reason: {row.recommendation_reason}, Score: {row.similarity_score:.2f}")

def evaluate_precision(session, recommendations):
    """Evaluate precision@5 using favorite_cars_by_user as ground truth."""
    query = "SELECT user_id, car_id FROM favorite_cars_by_user"
    rows = session.execute(SimpleStatement(query))
    ground_truth = {}
    for row in rows:
        user_id = str(row.user_id)
        if user_id not in ground_truth:
            ground_truth[user_id] = set()
        ground_truth[user_id].add(str(row.car_id))
    
    rec_df = pd.DataFrame(recommendations)
    precision = 0
    user_count = 0
    for user_id in rec_df['user_id'].unique():
        recommended = set(rec_df[rec_df['user_id'] == user_id]['car_id'].astype(str))
        favorites = ground_truth.get(str(user_id), set())
        if favorites:
            precision += len(recommended & favorites) / 5
            user_count += 1
    precision = precision / user_count if user_count > 0 else 0
    logging.info(f"Precision@5: {precision:.4f}")

def main():
    """Main function to run the recommendation pipeline."""
    session, cluster = setup_cassandra_session()
    try:
        data = fetch_data(session)
        recommendations = generate_recommendations(session, data)
        if recommendations:
            store_recommendations(session, recommendations)
            evaluate_precision(session, recommendations)
        logging.info("Hybrid recommendation process complete.")
    finally:
        cluster.shutdown()

if __name__ == "__main__":
    main()(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ pyhton  hybrid_recommendations.py
pyhton: command not found
(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ python  hybrid_recommendations.py
2025-05-13 13:35:32,703 - INFO - Connected to Cassandra cluster
2025-05-13 13:35:32,708 - INFO - Car_views_by_user rows: 157, Unique users: 52, Unique cars: 132
2025-05-13 13:35:32,712 - INFO - Favorite_cars_by_user rows: 109, Unique users: 53, Unique cars: 80
2025-05-13 13:35:32,717 - INFO - User_preferences rows: 55, Unique users: 55, Unique cars: 0
2025-05-13 13:35:32,732 - WARNING - Server warning: Read 633 live rows and 1472 tombstone cells for query SELECT brand, door_count, fuel_type, transmission FROM cars_keyspace.cleaned_cars LIMIT 5000 ALLOW FILTERING; token 9207834739780070790 (see tombstone_warn_threshold)
2025-05-13 13:35:32,733 - INFO - Cleaned_cars rows: 633, Unique users: 0, Unique cars: 0
2025-05-13 13:35:32,734 - WARNING - Table 'user_similarities' does not exist, skipping
2025-05-13 13:35:32,759 - INFO - User-item matrix shape: (53, 191)
2025-05-13 13:35:32,783 - INFO - SVD predictions shape: (53, 191)
2025-05-13 13:35:32,875 - INFO - Content-based similarity shape: (55, 633)
2025-05-13 13:35:32,878 - INFO - Hybrid scores shape: (53, 191)
2025-05-13 13:35:32,971 - INFO - Total recommendations generated: 265
2025-05-13 13:35:33,080 - INFO - Total recommendations stored: 265
2025-05-13 13:35:33,081 - INFO - Sample recommendations from database:
2025-05-13 13:35:33,081 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 06c110b1-9e53-4785-9db7-171c9ce7f033, Rank: 1, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.60), Score: 0.50
2025-05-13 13:35:33,081 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 19607e5b-848f-4a3d-86c1-5e56f490ecc7, Rank: 2, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.60), Score: 0.50
2025-05-13 13:35:33,081 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 219681b3-b450-460a-9b2d-42208fa2e173, Rank: 3, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.60), Score: 0.50
2025-05-13 13:35:33,081 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 21ff0142-15f6-4142-91eb-163478e9f020, Rank: 1, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.60), Score: 0.50
2025-05-13 13:35:33,081 - INFO - User: 588f2dc3-c048-4c61-a241-3bcd654a4404, Car: 242d3571-73ff-48ff-9bea-e978f8287859, Rank: 4, Reason: Hybrid: 0.50*collaborative (0.00) + 0.50*content-based (0.60), Score: 0.50
2025-05-13 13:35:33,109 - INFO - Precision@5: 0.0000
2025-05-13 13:35:33,109 - INFO - Hybrid recommendation process complete.
(cenv) hamzabji@lover:~/projects/cars_recommandation_pipeline/spark/models/recommendations$ 

 can wwe merge those dans un seul combined script python que on peut le lance pour generate recommendatins for user by id