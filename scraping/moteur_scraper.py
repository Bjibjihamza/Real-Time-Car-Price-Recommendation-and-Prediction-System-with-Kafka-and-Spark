import os
import re
import time
import json
import secrets
import string
import requests
import pandas as pd
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from kafka import KafkaProducer

# Configuration des rÃ©pertoires
DATA_DIR = "../data/moteur"
IMAGES_DIR = os.path.join("..", "backend", "images", "cars")
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(IMAGES_DIR, exist_ok=True)

# Configuration Kafka
KAFKA_BOOTSTRAP_SERVERS = 'localhost:9092'
KAFKA_TOPIC = 'moteur_cars'

def setup_kafka_producer():
    """Configure et initialise le producer Kafka."""
    try:
        producer = KafkaProducer(
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            key_serializer=lambda k: str(k).encode('utf-8')
        )
        print(f"âœ… Connexion rÃ©ussie au serveur Kafka: {KAFKA_BOOTSTRAP_SERVERS}")
        return producer
    except Exception as e:
        print(f"âŒ Erreur lors de la connexion Ã  Kafka: {e}")
        return None

def send_to_kafka(producer, topic, key, value):
    """Envoie un message Ã  un topic Kafka."""
    if producer is None:
        print("âš ï¸ Producer Kafka non disponible, message non envoyÃ©")
        return False
    try:
        future = producer.send(topic, key=key, value=value)
        result = future.get(timeout=60)
        print(f"âœ… Message envoyÃ© Ã  Kafka: topic={topic}, partition={result.partition}, offset={result.offset}")
        return True
    except Exception as e:
        print(f"âŒ Erreur lors de l'envoi Ã  Kafka: {e}")
        return False

def setup_driver():
    """Configure and initialize the Selenium driver."""
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--log-level=3")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def create_folder_name(title, idx):
    """CrÃ©e un nom de dossier court, alÃ©atoire et valide sans accents ni caractÃ¨res spÃ©ciaux."""
    random_part = ''.join(secrets.choice(string.ascii_lowercase + string.digits) for _ in range(12))
    folder_name = f"{random_part}_{idx}"
    return folder_name

def download_image(url, folder_path, index):
    """TÃ©lÃ©charge une image Ã  partir d'une URL avec des en-tÃªtes amÃ©liorÃ©s."""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    try:
        print(f"TÃ©lÃ©chargement de {url} vers {folder_path}")
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code == 200:
            file_extension = url.split('.')[-1]
            if '?' in file_extension:
                file_extension = file_extension.split('?')[0]
            if not file_extension or len(file_extension) > 5:
                file_extension = "jpg"
            image_path = os.path.join(folder_path, f"image_{index}.{file_extension}")
            with open(image_path, 'wb') as f:
                f.write(response.content)
            print(f"âœ… Image enregistrÃ©e : {image_path}")
            return True
        else:
            print(f"âŒ Erreur HTTP {response.status_code} pour {url}")
        return False
    except Exception as e:
        print(f"âš ï¸ Erreur lors du tÃ©lÃ©chargement de l'image {url}: {e}")
        return False

def extract_id_from_url(url):
    """Extrait l'ID de l'annonce Ã  partir de l'URL."""
    match = re.search(r"/detail-annonce/(\d+)/", url)
    return match.group(1) if match else "N/A"

def scrape_listings_page(driver, page_number):
    """Scrape la page des annonces."""
    BASE_URL = "https://www.moteur.ma/fr/voiture/achat-voiture-occasion/"
    offset = (page_number - 1) * 30
    page_url = f"{BASE_URL}{offset}" if offset > 0 else BASE_URL
    print(f"ğŸ” Scraping page {page_number}: {page_url}")
    driver.get(page_url)
    try:
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CLASS_NAME, "row-item"))
        )
    except:
        print(f"âŒ Aucune annonce trouvÃ©e sur la page {page_number} !")
        return []
    car_elements = driver.find_elements(By.CLASS_NAME, "row-item")
    print(f"âœ… {len(car_elements)} annonces trouvÃ©es sur la page {page_number} !")
    data = []
    for car in car_elements:
        try:
            title_element = car.find_element(By.CLASS_NAME, "title_mark_model")
            title = title_element.text.strip() if title_element else "N/A"
            try:
                link_element = car.find_element(By.XPATH, ".//h3[@class='title_mark_model']/a")
                link = link_element.get_attribute("href") if link_element else "N/A"
                ad_id = extract_id_from_url(link)
            except:
                link, ad_id = "N/A", "N/A"
            try:
                price_element = car.find_element(By.CLASS_NAME, "PriceListing")
                price = price_element.text.strip()
            except:
                price = "N/A"
            meta_elements = car.find_elements(By.TAG_NAME, "li")
            year = "N/A"
            city = "N/A"
            fuel = "N/A"
            forbidden_values = ["Appeler pour le prix", "Se faire rappeler", "Booster l'annonce", ""]
            for li in meta_elements:
                text = li.text.strip()
                if re.match(r"^(19|20)\d{2}$", text):
                    year = text
                elif text.lower() in ["essence", "diesel", "hybride", "Ã©lectrique"]:
                    fuel = text.capitalize()
                elif city == "N/A" and text not in forbidden_values:
                    city = text
            if city in forbidden_values or city == "N/A":
                print(f"âš ï¸ Ville douteuse pour l'annonce ID {ad_id} : '{city}' - {link}")
            data.append({
                "ID": ad_id,
                "Titre": title,
                "Prix": price,
                "AnnÃ©e": year,
                "Type de carburant": fuel,
                "Ville": city,
                "URL de l'annonce": link
            })
        except Exception as e:
            print(f"âš ï¸ Erreur avec une annonce: {e}")
    time.sleep(3)
    return data

def scrape_detail_page(driver, url, ad_id, title, price, idx):
    """Scrape les dÃ©tails d'une annonce spÃ©cifique."""
    try:
        driver.get(url)
        time.sleep(3)
        folder_name = create_folder_name(title, idx)
        folder_path = os.path.join(IMAGES_DIR, folder_name)
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
            print(f"ğŸ“‚ Dossier crÃ©Ã© : {folder_path}")
        location = "N/A"
        mileage = "N/A"
        brand = "N/A"
        model = "N/A"
        doors = "N/A"
        first_hand = "N/A"
        fiscal_power = "N/A"
        equipment_text = "N/A"
        seller_city = "N/A"
        dedouane = "N/A"
        transmission = "N/A"
        fuel_type = "N/A"
        creator = "N/A"
        try:
            creator_element = driver.find_element(By.XPATH, "//a[.//i[contains(@class, 'icon-normal-megaphone')]]")
            if creator_element:
                creator = creator_element.text.strip()
            if creator == "N/A":
                creator_element = driver.find_element(By.XPATH, "//div[@class='actions block_tele']//li/a[i[contains(@class, 'icon-normal-megaphone')]]")
                creator = creator_element.text.strip()
        except Exception as e:
            print(f"Erreur extraction du crÃ©ateur: {e}")
            try:
                creator_element = driver.find_element(By.XPATH, "//div[@class='block-inner block-detail-ad']//div[@class='actions block_tele']//a[contains(@href, 'stock-professionnel')]")
                creator = creator_element.text.strip()
            except Exception as e2:
                print(f"Erreur extraction du crÃ©ateur (mÃ©thode alternative): {e2}")
        try:
            transmission_element = driver.find_element(By.XPATH, "//span[contains(text(), 'Boite de vitesses')]/following-sibling::span")
            transmission = transmission_element.text.strip()
        except Exception as e:
            print(f"Erreur extraction directe de transmission: {e}")
        detail_lines = driver.find_elements(By.CLASS_NAME, "detail_line")
        for line in detail_lines:
            try:
                spans = line.find_elements(By.TAG_NAME, "span")
                if len(spans) >= 2:
                    key = spans[0].text.strip()
                    value = spans[1].text.strip()
                    if "KilomÃ©trage" in key:
                        mileage = value
                    elif "Boite de vitesses" in key:
                        transmission = value
                    elif "Carburant" in key:
                        fuel_type = value
                    elif "Puissance fiscale" in key:
                        fiscal_power = value
                    elif "Nombre de portes" in key:
                        doors = value
                    elif "PremiÃ¨re main" in key:
                        first_hand = value
                    elif "VÃ©hicule dÃ©douanÃ©" in key:
                        dedouane = value
            except Exception as e:
                print(f"Erreur lors de l'extraction d'une ligne de dÃ©tail: {e}")
        try:
            description_element = driver.find_element(By.CSS_SELECTOR, "div.options div.col-md-12")
            equipment_text = description_element.text.strip()
        except Exception as e:
            print(f"Erreur extraction description: {e}")
        try:
            city_element = driver.find_element(By.XPATH, "//a[contains(@href, 'ville')]")
            seller_city = city_element.text.strip()
            location = seller_city
        except Exception as e:
            print(f"Erreur extraction ville: {e}")
        image_count = 0
        try:
            image_elements = driver.find_elements(By.CSS_SELECTOR, "img[data-u='image']")
            for index, img in enumerate(image_elements):
                img_url = img.get_attribute("src")
                if img_url and "http" in img_url:
                    success = download_image(img_url, folder_path, index + 1)
                    if success:
                        image_count += 1
        except Exception as e:
            print(f"Erreur lors de l'extraction des images: {e}")
        try:
            title_parts = title.split()
            if len(title_parts) >= 2:
                brand = title_parts[0].upper()
                model = title_parts[1].capitalize()
        except Exception as e:
            print(f"Erreur lors de l'extraction de la marque et du modÃ¨le depuis le titre: {e}")
        detail_data = {
            "ID": ad_id,
            "Titre": title,
            "Prix": price,
            "Date de publication": datetime.now().strftime("%Y-%m-%d"),
            "Type de carburant": fuel_type,
            "Transmission": transmission,
            "CrÃ©ateur": creator,
            "Secteur": location,
            "KilomÃ©trage": mileage,
            "Marque": brand,
            "ModÃ¨le": model,
            "Nombre de portes": doors,
            "PremiÃ¨re main": first_hand,
            "Puissance fiscale": fiscal_power,
            "Ã‰quipements": equipment_text,
            "Ville du vendeur": seller_city,
            "Dossier d'images": folder_name,
            "DÃ©douanÃ©": dedouane
        }
        return detail_data
    except Exception as e:
        print(f"âŒ Erreur lors du scraping de la page {url}: {e}")
        return {
            "ID": ad_id,
            "Titre": title,
            "Prix": price,
            "Date de publication": datetime.now().strftime("%Y-%m-%d"),
            "Type de carburant": "N/A",
            "Transmission": "N/A",
            "CrÃ©ateur": "N/A" ,
            "Secteur": "N/A",
            "KilomÃ©trage": "N/A",
            "Marque": "N/A",
            "ModÃ¨le": "N/A",
            "Nombre de portes": "N/A",
            "PremiÃ¨re main": "N/A",
            "Puissance fiscale": "N/A",
            "Ã‰quipements": "N/A",
            "Ville du vendeur": "N/A",
            "Dossier d'images": folder_name,
            "DÃ©douanÃ©": "N/A"
        }

def main():
    """Fonction principale qui exÃ©cute le scraper complet."""
    print("ğŸš— DÃ©marrage du scraper complet Moteur.ma...")
    driver = setup_driver()
    kafka_producer = setup_kafka_producer()
    try:
        print("\nğŸ“‹ RÃ©cupÃ©ration des annonces de la page 1...")
        listings_data = scrape_listings_page(driver, 55)
        if not listings_data:
            print("âŒ Aucune annonce trouvÃ©e. ArrÃªt du programme.")
            driver.quit()
            return
        print(f"âœ… {len(listings_data)} annonces rÃ©cupÃ©rÃ©es.")
        print("\nğŸ” RÃ©cupÃ©ration des dÃ©tails pour chaque annonce...")
        detailed_data = []
        for idx, listing in enumerate(listings_data, start=1):
            print(f"\nâ¡ï¸ Traitement de l'annonce {idx}/{len(listings_data)}: {listing['Titre']}")
            detail = scrape_detail_page(
                driver,
                listing["URL de l'annonce"],
                listing['ID'],
                listing['Titre'],
                listing['Prix'],
                idx
            )
            if kafka_producer:
                print(f"ğŸ“¤ Envoi des donnÃ©es de l'annonce {detail['ID']} Ã  Kafka...")
                send_to_kafka(kafka_producer, KAFKA_TOPIC, detail['ID'], detail)
            detailed_data.append(detail)
            time.sleep(2)
        output_file = os.path.join(DATA_DIR, f"moteur_complete.csv")
        df = pd.DataFrame(detailed_data)
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print("\nâœ… SCRAPING TERMINÃ‰ AVEC SUCCÃˆS!")
        print(f"ğŸ“Š {len(detailed_data)} annonces complÃ¨tes rÃ©cupÃ©rÃ©es.")
        print(f"ğŸ“„ DonnÃ©es enregistrÃ©es dans: {output_file}")
        print(f"ğŸ–¼ï¸ Images tÃ©lÃ©chargÃ©es dans: {IMAGES_DIR}")
        print(f"ğŸ“¡ DonnÃ©es envoyÃ©es au topic Kafka: {KAFKA_TOPIC}")
    except Exception as e:
        print(f"âŒ Erreur globale: {e}")
    finally:
        if kafka_producer:
            kafka_producer.flush()
            kafka_producer.close()
            print("ğŸ”Œ Producer Kafka fermÃ©.")
        driver.quit()
        print("ğŸ Programme terminÃ©.")

if __name__ == "__main__":
    main()