import os
import re
import time
import json
import secrets
import string
import requests
import pandas as pd
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from kafka import KafkaProducer

# Configuration des r√©pertoires
DATA_DIR = "../data/moteur"
IMAGES_DIR = os.path.join("..", "backend", "images", "cars")
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(IMAGES_DIR, exist_ok=True)

# Configuration Kafka
KAFKA_BOOTSTRAP_SERVERS = 'localhost:9092'
KAFKA_TOPIC = 'moteur_cars'

def setup_kafka_producer():
    """Configure et initialise le producer Kafka."""
    try:
        producer = KafkaProducer(
            bootstrap_servers=KAFKA_BOOTSTRAP_SERVERS,
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            key_serializer=lambda k: str(k).encode('utf-8')
        )
        print(f"‚úÖ Connexion r√©ussie au serveur Kafka: {KAFKA_BOOTSTRAP_SERVERS}")
        return producer
    except Exception as e:
        print(f"‚ùå Erreur lors de la connexion √† Kafka: {e}")
        return None

def send_to_kafka(producer, topic, key, value):
    """Envoie un message √† un topic Kafka."""
    if producer is None:
        print("‚ö†Ô∏è Producer Kafka non disponible, message non envoy√©")
        return False
    try:
        future = producer.send(topic, key=key, value=value)
        result = future.get(timeout=60)
        print(f"‚úÖ Message envoy√© √† Kafka: topic={topic}, partition={result.partition}, offset={result.offset}")
        return True
    except Exception as e:
        print(f"‚ùå Erreur lors de l'envoi √† Kafka: {e}")
        return False

def setup_driver():
    """Configure and initialize the Selenium driver."""
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--log-level=3")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)
    return driver

def create_folder_name(title, idx):
    """Cr√©e un nom de dossier court, al√©atoire et valide sans accents ni caract√®res sp√©ciaux."""
    random_part = ''.join(secrets.choice(string.ascii_lowercase + string.digits) for _ in range(12))
    folder_name = f"{random_part}_{idx}"
    return folder_name

def download_image(url, folder_path, index):
    """T√©l√©charge une image √† partir d'une URL avec des en-t√™tes am√©lior√©s."""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    try:
        print(f"T√©l√©chargement de {url} vers {folder_path}")
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code == 200:
            file_extension = url.split('.')[-1]
            if '?' in file_extension:
                file_extension = file_extension.split('?')[0]
            if not file_extension or len(file_extension) > 5:
                file_extension = "jpg"
            image_path = os.path.join(folder_path, f"image_{index}.{file_extension}")
            with open(image_path, 'wb') as f:
                f.write(response.content)
            print(f"‚úÖ Image enregistr√©e : {image_path}")
            return True
        else:
            print(f"‚ùå Erreur HTTP {response.status_code} pour {url}")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du t√©l√©chargement de l'image {url}: {e}")
        return False

def extract_id_from_url(url):
    """Extrait l'ID de l'annonce √† partir de l'URL."""
    match = re.search(r"/detail-annonce/(\d+)/", url)
    return match.group(1) if match else "N/A"

def scrape_listings_page(driver, page_number):
    """Scrape la page des annonces."""
    BASE_URL = "https://www.moteur.ma/fr/voiture/achat-voiture-occasion/"
    offset = (page_number - 1) * 30
    page_url = f"{BASE_URL}{offset}" if offset > 0 else BASE_URL
    print(f"üîé Scraping page {page_number}: {page_url}")
    driver.get(page_url)
    try:
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CLASS_NAME, "row-item"))
        )
    except:
        print(f"‚ùå Aucune annonce trouv√©e sur la page {page_number} !")
        return []
    car_elements = driver.find_elements(By.CLASS_NAME, "row-item")
    print(f"‚úÖ {len(car_elements)} annonces trouv√©es sur la page {page_number} !")
    data = []
    for car in car_elements:
        try:
            title_element = car.find_element(By.CLASS_NAME, "title_mark_model")
            title = title_element.text.strip() if title_element else "N/A"
            try:
                link_element = car.find_element(By.XPATH, ".//h3[@class='title_mark_model']/a")
                link = link_element.get_attribute("href") if link_element else "N/A"
                ad_id = extract_id_from_url(link)
            except:
                link, ad_id = "N/A", "N/A"
            try:
                price_element = car.find_element(By.CLASS_NAME, "PriceListing")
                price = price_element.text.strip()
            except:
                price = "N/A"
            meta_elements = car.find_elements(By.TAG_NAME, "li")
            year = "N/A"
            city = "N/A"
            fuel = "N/A"
            forbidden_values = ["Appeler pour le prix", "Se faire rappeler", "Booster l'annonce", ""]
            for li in meta_elements:
                text = li.text.strip()
                if re.match(r"^(19|20)\d{2}$", text):
                    year = text
                elif text.lower() in ["essence", "diesel", "hybride", "√©lectrique"]:
                    fuel = text.capitalize()
                elif city == "N/A" and text not in forbidden_values:
                    city = text
            if city in forbidden_values or city == "N/A":
                print(f"‚ö†Ô∏è Ville douteuse pour l'annonce ID {ad_id} : '{city}' - {link}")
            data.append({
                "ID": ad_id,
                "Titre": title,
                "Prix": price,
                "Ann√©e": year,
                "Type de carburant": fuel,
                "Ville": city,
                "URL de l'annonce": link
            })
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur avec une annonce: {e}")
    time.sleep(3)
    return data

def scrape_detail_page(driver, url, ad_id, title, price, idx):
    """Scrape les d√©tails d'une annonce sp√©cifique."""
    try:
        driver.get(url)
        time.sleep(3)
        folder_name = create_folder_name(title, idx)
        folder_path = os.path.join(IMAGES_DIR, folder_name)
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
            print(f"üìÇ Dossier cr√©√© : {folder_path}")
        location = "N/A"
        mileage = "N/A"
        brand = "N/A"
        model = "N/A"
        doors = "N/A"
        first_hand = "N/A"
        fiscal_power = "N/A"
        equipment_text = "N/A"
        seller_city = "N/A"
        dedouane = "N/A"
        transmission = "N/A"
        fuel_type = "N/A"
        creator = "N/A"
        try:
            creator_element = driver.find_element(By.XPATH, "//a[.//i[contains(@class, 'icon-normal-megaphone')]]")
            if creator_element:
                creator = creator_element.text.strip()
            if creator == "N/A":
                creator_element = driver.find_element(By.XPATH, "//div[@class='actions block_tele']//li/a[i[contains(@class, 'icon-normal-megaphone')]]")
                creator = creator_element.text.strip()
        except Exception as e:
            print(f"Erreur extraction du cr√©ateur: {e}")
            try:
                creator_element = driver.find_element(By.XPATH, "//div[@class='block-inner block-detail-ad']//div[@class='actions block_tele']//a[contains(@href, 'stock-professionnel')]")
                creator = creator_element.text.strip()
            except Exception as e2:
                print(f"Erreur extraction du cr√©ateur (m√©thode alternative): {e2}")
        try:
            transmission_element = driver.find_element(By.XPATH, "//span[contains(text(), 'Boite de vitesses')]/following-sibling::span")
            transmission = transmission_element.text.strip()
        except Exception as e:
            print(f"Erreur extraction directe de transmission: {e}")
        detail_lines = driver.find_elements(By.CLASS_NAME, "detail_line")
        for line in detail_lines:
            try:
                spans = line.find_elements(By.TAG_NAME, "span")
                if len(spans) >= 2:
                    key = spans[0].text.strip()
                    value = spans[1].text.strip()
                    if "Kilom√©trage" in key:
                        mileage = value
                    elif "Boite de vitesses" in key:
                        transmission = value
                    elif "Carburant" in key:
                        fuel_type = value
                    elif "Puissance fiscale" in key:
                        fiscal_power = value
                    elif "Nombre de portes" in key:
                        doors = value
                    elif "Premi√®re main" in key:
                        first_hand = value
                    elif "V√©hicule d√©douan√©" in key:
                        dedouane = value
            except Exception as e:
                print(f"Erreur lors de l'extraction d'une ligne de d√©tail: {e}")
        try:
            description_element = driver.find_element(By.CSS_SELECTOR, "div.options div.col-md-12")
            equipment_text = description_element.text.strip()
        except Exception as e:
            print(f"Erreur extraction description: {e}")
        try:
            city_element = driver.find_element(By.XPATH, "//a[contains(@href, 'ville')]")
            seller_city = city_element.text.strip()
            location = seller_city
        except Exception as e:
            print(f"Erreur extraction ville: {e}")
        image_count = 0
        try:
            image_elements = driver.find_elements(By.CSS_SELECTOR, "img[data-u='image']")
            for index, img in enumerate(image_elements):
                img_url = img.get_attribute("src")
                if img_url and "http" in img_url:
                    success = download_image(img_url, folder_path, index + 1)
                    if success:
                        image_count += 1
        except Exception as e:
            print(f"Erreur lors de l'extraction des images: {e}")
        try:
            title_parts = title.split()
            if len(title_parts) >= 2:
                brand = title_parts[0].upper()
                model = title_parts[1].capitalize()
        except Exception as e:
            print(f"Erreur lors de l'extraction de la marque et du mod√®le depuis le titre: {e}")
        detail_data = {
            "ID": ad_id,
            "Titre": title,
            "Prix": price,
            "Date de publication": datetime.now().strftime("%Y-%m-%d"),
            "Type de carburant": fuel_type,
            "Transmission": transmission,
            "Cr√©ateur": creator,
            "Secteur": location,
            "Kilom√©trage": mileage,
            "Marque": brand,
            "Mod√®le": model,
            "Nombre de portes": doors,
            "Premi√®re main": first_hand,
            "Puissance fiscale": fiscal_power,
            "√âquipements": equipment_text,
            "Ville du vendeur": seller_city,
            "Dossier d'images": folder_name,
            "D√©douan√©": dedouane
        }
        return detail_data
    except Exception as e:
        print(f"‚ùå Erreur lors du scraping de la page {url}: {e}")
        return {
            "ID": ad_id,
            "Titre": title,
            "Prix": price,
            "Date de publication": datetime.now().strftime("%Y-%m-%d"),
            "Type de carburant": "N/A",
            "Transmission": "N/A",
            "Cr√©ateur": "N/A" ,
            "Secteur": "N/A",
            "Kilom√©trage": "N/A",
            "Marque": "N/A",
            "Mod√®le": "N/A",
            "Nombre de portes": "N/A",
            "Premi√®re main": "N/A",
            "Puissance fiscale": "N/A",
            "√âquipements": "N/A",
            "Ville du vendeur": "N/A",
            "Dossier d'images": folder_name,
            "D√©douan√©": "N/A"
        }

def main():
    """Fonction principale qui ex√©cute le scraper complet."""
    print("üöó D√©marrage du scraper complet Moteur.ma...")
    driver = setup_driver()
    kafka_producer = setup_kafka_producer()
    try:
        print("\nüìã R√©cup√©ration des annonces de la page 1...")
        listings_data = scrape_listings_page(driver, 55)
        if not listings_data:
            print("‚ùå Aucune annonce trouv√©e. Arr√™t du programme.")
            driver.quit()
            return
        print(f"‚úÖ {len(listings_data)} annonces r√©cup√©r√©es.")
        print("\nüîç R√©cup√©ration des d√©tails pour chaque annonce...")
        detailed_data = []
        for idx, listing in enumerate(listings_data, start=1):
            print(f"\n‚û°Ô∏è Traitement de l'annonce {idx}/{len(listings_data)}: {listing['Titre']}")
            detail = scrape_detail_page(
                driver,
                listing["URL de l'annonce"],
                listing['ID'],
                listing['Titre'],
                listing['Prix'],
                idx
            )
            if kafka_producer:
                print(f"üì§ Envoi des donn√©es de l'annonce {detail['ID']} √† Kafka...")
                send_to_kafka(kafka_producer, KAFKA_TOPIC, detail['ID'], detail)
            detailed_data.append(detail)
            time.sleep(2)
        output_file = os.path.join(DATA_DIR, f"moteur_complete.csv")
        df = pd.DataFrame(detailed_data)
        df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print("\n‚úÖ SCRAPING TERMIN√â AVEC SUCC√àS!")
        print(f"üìä {len(detailed_data)} annonces compl√®tes r√©cup√©r√©es.")
        print(f"üìÑ Donn√©es enregistr√©es dans: {output_file}")
        print(f"üñºÔ∏è Images t√©l√©charg√©es dans: {IMAGES_DIR}")
        print(f"üì° Donn√©es envoy√©es au topic Kafka: {KAFKA_TOPIC}")
    except Exception as e:
        print(f"‚ùå Erreur globale: {e}")
    finally:
        if kafka_producer:
            kafka_producer.flush()
            kafka_producer.close()
            print("üîå Producer Kafka ferm√©.")
        driver.quit()
        print("üèÅ Programme termin√©.")

if __name__ == "__main__":
    main()